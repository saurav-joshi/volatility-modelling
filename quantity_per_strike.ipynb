{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mibian\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def calc_implied_vol_delta_and_parity(row, underlying_price, days_to_expiry):\n",
    "    interest_rate = 0.046\n",
    "    delta_type = {'C': 'callDelta', 'P': 'putDelta', 'ATM Avg Put/Call': 'putDelta'}\n",
    "\n",
    "    def calculate_mibian_bs(call_price, put_price, implied_vol=None):\n",
    "        if implied_vol is None:\n",
    "            ###print(f'Call Price: {call_price}, Put Price: {put_price}')\n",
    "            c = mibian.BS([underlying_price, row['strike'], interest_rate, days_to_expiry], callPrice=call_price, putPrice=put_price)\n",
    "            implied_vol = c.impliedVolatility\n",
    "        c = mibian.BS([underlying_price, row['strike'], interest_rate, days_to_expiry], volatility=implied_vol)\n",
    "        delta = getattr(c, delta_type[row['option_type']])\n",
    "        return implied_vol, delta\n",
    "\n",
    "    call_price, put_price = (row['mid_quote'], None) if row['option_type'] == 'C' else (None, row['mid_quote'])\n",
    "    implied_vol, delta = calculate_mibian_bs(call_price, put_price)\n",
    "\n",
    "\n",
    "    return pd.Series([implied_vol, delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vix_index:  19.793164332117087\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_quantity_per_strike(row, vix_index):\n",
    "    # Calculate the quantity per strike\n",
    "    q  = (10000 *row.per_strike_constants)/(2*vix_index) \n",
    "    return q\n",
    "\n",
    "\n",
    "expiry_date = '20230317'\n",
    "observation_date = '2023-02-07'\n",
    "inst_type = 'future'\n",
    "working_dataset = f'./result-set/{observation_date}/{inst_type}/dataset_{expiry_date}.csv'\n",
    "df = pd.read_csv(working_dataset)\n",
    "vix_index = df['vix_forward'].iloc[0]\n",
    "print(\"vix_index: \", vix_index)\n",
    "\n",
    "df['quantity'] = df.apply(calculate_quantity_per_strike, axis=1, args=(vix_index,))\n",
    "df.to_csv(working_dataset, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "option_expiry = '20230317'\n",
    "trade_date = '2023-02-07'\n",
    "settlement_date = '2023-02-15'\n",
    "\n",
    "\n",
    "# Load the datasets\n",
    "df1 = pd.read_csv(f'./result-set/{trade_date}/future/dataset_{option_expiry}.csv')\n",
    "df2 = pd.read_csv(f'./result-set/{settlement_date}/future/dataset_complete_{option_expiry}.csv')\n",
    "\n",
    "def get_future_price_new(row, df2):\n",
    "    if row['option_type'] == 'ATM Avg Put/Call':\n",
    "        matching_rows = df2[df2['strike'] == row['strike']]\n",
    "        if not matching_rows.empty:\n",
    "            future_price = matching_rows['mid_quote'].mean()\n",
    "            pl = row['quantity'] * (future_price - row['mid_quote'])\n",
    "            return pd.Series([future_price, pl])\n",
    "    else:\n",
    "        matching_row = df2[(df2['strike'] == row['strike']) & (df2['option_type'] == row['option_type'])]\n",
    "        if not matching_row.empty:\n",
    "            future_price = matching_row['mid_quote'].values[0]\n",
    "            pl = row['quantity'] * (future_price - row['mid_quote'])\n",
    "            return pd.Series([future_price, pl])\n",
    "    return pd.Series([None, None])\n",
    "\n",
    "# Create the new column\n",
    "df1[['future_prices', 'P&L']] = df1.apply(get_future_price_new, args=(df2,), axis=1)\n",
    "df_final = df1[['strike', 'option_type', 'mid_quote', 'future_prices', 'quantity','vix_forward', 'P&L']].copy()\n",
    "df_final.to_csv(f'./result-set/{trade_date}/P&L/dataset_{option_expiry}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "option_expiry_near = '20230421'\n",
    "option_expiry_next = '20230428'\n",
    "trade_date = '2023-03-21'\n",
    "\n",
    "# Load the datasets\n",
    "df_near = pd.read_csv(f'./result-set/{trade_date}/P&L/dataset_{option_expiry_near}.csv')\n",
    "df_next = pd.read_csv(f'./result-set/{trade_date}/P&L/dataset_{option_expiry_next}.csv')\n",
    "\n",
    "df = pd.concat([df_near, df_next])\n",
    "df.to_csv(f'./result-set/{trade_date}/P&L/consolidated-dataset_{trade_date}.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory you want to read from\n",
    "directory = './result-set/P&L_across_days/'\n",
    "\n",
    "# Create a list to hold all the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):  # Assuming the files are CSVs\n",
    "        # Read the file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "\n",
    "        # Add the dataframe to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "consolidated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the consolidated dataframe to a new CSV file\n",
    "consolidated_df.to_csv('./result-set/P&L_across_days/consolidated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import vix_utils\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory you want to read from\n",
    "parent_directory = './result-set/'\n",
    "def calculate_greeks_add_future_prices():\n",
    "    \n",
    "    # Create a dictionary to hold the dataframes\n",
    "    dataframes = {}\n",
    "\n",
    "    # Iterate over all subdirectories in the parent directory\n",
    "    for trade_date in os.listdir(parent_directory):\n",
    "        # Construct the path to the 'future' directory\n",
    "        future_directory = os.path.join(parent_directory, trade_date, 'future')\n",
    "\n",
    "        # Check if the 'future' directory exists\n",
    "        if os.path.isdir(future_directory):\n",
    "            # Iterate over all files in the 'future' directory\n",
    "            for filename in os.listdir(future_directory):\n",
    "                # Check if the file matches the pattern 'dataset_*.csv' and does not start with 'dataset_complete_'\n",
    "                if filename.startswith('dataset_') and not filename.startswith('dataset_complete_') and filename.endswith('.csv'):\n",
    "                    # Construct the full file path\n",
    "                    file_path = os.path.join(future_directory, filename)\n",
    "\n",
    "                    # Read the file into a dataframe\n",
    "                    df = pd.read_csv(file_path)\n",
    "                    expiry_date = filename.split('_')[1].split('.')[0]\n",
    "                    vix_index = df['vix_forward'].iloc[0]\n",
    "                    df['quantity'] = df.apply(calculate_quantity_per_strike, axis=1, args=(vix_index,))\n",
    "\n",
    "                    df = add_vol_and_delta(df,trade_date, expiry_date)\n",
    "\n",
    "                    df.to_csv(file_path, index=False)\n",
    "    ######################################################################################################\n",
    "                    # Split trade_date into year, month, and day\n",
    "                    year, month, day = trade_date.split('-')\n",
    "                    future_settlement_date = vix_utils.vix_futures_expiry_date_from_trade_date(int(year), int(month), int(day), 1).strftime('%Y-%m-%d')\n",
    "                    future_settlement_directory = os.path.join(parent_directory, future_settlement_date, 'future')\n",
    "\n",
    "                    filtered_df = vix_futures[(vix_futures['Trade Date'] == trade_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "                    settlement_df = vix_futures[(vix_futures['Trade Date'] == future_settlement_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "                    if not filtered_df.empty:\n",
    "                        vix_futures_on_trade_day = filtered_df['Close'].values[0]\n",
    "                        vix_futures_on_settlement_day = settlement_df['Close'].values[0]\n",
    "    ######################################################################################################                \n",
    "                    \n",
    "                    #complete_file_path = os.path.join(future_directory, 'dataset_complete_' + filename[8:])\n",
    "                    complete_file_path = os.path.join(future_settlement_directory, 'dataset_complete_' + filename[8:])\n",
    "                    if os.path.isfile(complete_file_path):\n",
    "                        \n",
    "                        df_complete = pd.read_csv(complete_file_path)\n",
    "                        df[['future_prices', 'P&L']] = df.apply(get_future_price_new, args=(df_complete,), axis=1)\n",
    "                        df_final = df[['strike', 'option_type','per_strike_constants', 'mid_quote', 'future_prices', 'quantity','vix_forward','Implied Vol','delta']].copy()\n",
    "                        # Construct the path to the 'P&L' directory\n",
    "                        pl_directory = future_directory.replace('future', 'P&L')\n",
    "\n",
    "                        filtered_df = vix_futures[(vix_futures['Trade Date'] == trade_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "                        if not filtered_df.empty:\n",
    "                            vix_futures_on_trade_day = filtered_df['Close'].values[0]\n",
    "                            df_final['vix_future_trade_day'] = vix_futures_on_trade_day\n",
    "                            df_final['vix_future_settlment_day'] = vix_futures_on_settlement_day\n",
    "\n",
    "                            df_final_abridged = df_final[['strike', 'option_type','per_strike_constants', 'mid_quote', 'future_prices', \n",
    "                                                          'quantity','vix_forward','vix_future_trade_day', 'vix_future_settlment_day','Implied Vol','delta']].copy()\n",
    "\n",
    "                        # Check if the 'P&L' directory exists, if not, create it\n",
    "                        if not os.path.exists(pl_directory):\n",
    "                            os.makedirs(pl_directory)\n",
    "                        # Save the merged dataframe in the 'P&L' directory\n",
    "                        df_final.to_csv(os.path.join(pl_directory, filename), index=False)\n",
    "                        ######df_final_abridged.to_csv(os.path.join(pl_directory, 'abridged_' + filename), index=False)\n",
    "\n",
    "                    prefix = 'filtered_delta_strikes_'\n",
    "                    new_file_path = file_path.replace('future', 'P&L')\n",
    "                    df_filter = pd.read_csv(new_file_path)\n",
    "                    ###df_filter = filter_delta_trial(df_filter)\n",
    "                    df_filter = filter_delta_trial_latest(df_filter)\n",
    "                    #df_filter = filter_delta_new(df_filter)\n",
    "                    \n",
    "\n",
    "                    df_filter = df_filter[['strike', 'option_type','per_strike_constants', 'mid_quote', 'future_prices','vix_forward',\n",
    "                                          'vix_future_trade_day', 'vix_future_settlment_day','original_quantity', 'quantity_added','quantity',  'Implied Vol','delta']]\n",
    "                    df_filter.to_csv(os.path.join(pl_directory, prefix + filename), index=False)\n",
    "\n",
    "\n",
    "        pl_dir = future_directory.replace('future', 'P&L')\n",
    "        print(\"pl_dir: \", pl_dir)\n",
    "        file_patterns = ['dataset_*.csv', 'filtered_delta_strikes_dataset_*.csv']\n",
    "\n",
    "        # Loop over the file patterns\n",
    "        for file_pattern in file_patterns:\n",
    "            # Construct the full file pattern\n",
    "            full_file_pattern = os.path.join(pl_dir, file_pattern)\n",
    "\n",
    "            # Get a list of all files that match the pattern\n",
    "            file_list = glob.glob(full_file_pattern)\n",
    "\n",
    "            # Check if the file list is empty\n",
    "            if not file_list:\n",
    "                print(f\"No files found with the pattern {file_pattern}.\")\n",
    "            else:\n",
    "                # Initialize an empty list to store the dataframes\n",
    "                df_list = []\n",
    "\n",
    "                # Loop over the file list\n",
    "                for file in file_list:\n",
    "                    # Load the file into a DataFrame and append it to the list\n",
    "                    df_list.append(pd.read_csv(file))\n",
    "\n",
    "                # Concatenate all the dataframes in the list\n",
    "                df = pd.concat(df_list)\n",
    "                #Add P&L column\n",
    "                df['P&L-per-strike'] = df.apply(pl_per_strike, axis=1)\n",
    "\n",
    "\n",
    "                # Create a unique output file name based on the file pattern\n",
    "                output_file_name = file_pattern.replace('*', 'concatenated')\n",
    "\n",
    "                # Save the concatenated dataframe to a new file\n",
    "                df.to_csv(os.path.join(pl_dir, output_file_name), index=False)\n",
    "                \n",
    "                ####Total P&L contribution\n",
    "                # future_pl, basket_pl, total_pl, strategy = pl_per_day(df)\n",
    "                # #####################\n",
    "                # df.to_csv(os.path.join(pl_dir, 'P&L_calculator.csv'), index=False)\n",
    "                # ##########################    \n",
    "                # parent_directory_temp = os.path.dirname(pl_directory)\n",
    "                # trade_date = parent_directory_temp.split('/')[-1]\n",
    "                # df_per_day_PL = pd.DataFrame({\n",
    "                #     'trade_date': [trade_date],\n",
    "                #     'vix-forward': [df['vix_forward'].iloc[0]],  \n",
    "                #     'vix-futures-trade-day': [df['vix_future_trade_day'].iloc[0]],\n",
    "                #     'vix-futures-settlement-day': [df['vix_future_settlment_day'].iloc[0]],\n",
    "                #     'future-P&L':[future_pl], \n",
    "                #     'basket-P&L' : [basket_pl],\n",
    "                #     'total-P&L' : [total_pl],\n",
    "                #     'strategy' : [strategy]\n",
    "                #     })\n",
    "                # file_name = f'P&L_for_{trade_date}.csv'\n",
    "                # directory = os.path.join('./result-set', 'P&L-across-days')\n",
    "                # # Create the directory if it does not exist\n",
    "                # os.makedirs(directory, exist_ok=True)\n",
    "                # file_path = os.path.join(directory, file_name)\n",
    "                # df_per_day_PL.to_csv(file_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vol_and_delta(df, trade_date, expiry_date):\n",
    "    days_to_expiry = (datetime.datetime.strptime(expiry_date, \"%Y%m%d\") - datetime.datetime.strptime(trade_date, \"%Y-%m-%d\")).days\n",
    "    forward = df[df['option_type'] == 'ATM Avg Put/Call']['strike'].values[0]\n",
    "    df[['Implied Vol', 'delta']] = df.apply(calc_implied_vol_delta_and_parity, args=(forward, days_to_expiry), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_per_day(df):\n",
    "\n",
    "    vix_forward = df['vix_forward'].iloc[0]\n",
    "    vix_future_trade_day = df['vix_future_trade_day'].iloc[0]\n",
    "    vix_future_settlment_day = df['vix_future_settlment_day'].iloc[0]\n",
    "    \n",
    "    def calculate(row):\n",
    "        return (row['future_prices'] - row['mid_quote']) * row['quantity']\n",
    "    \n",
    "    basket_pl = df.apply(calculate, axis=1).sum()\n",
    "    future_pl = (vix_future_settlment_day - vix_future_trade_day)\n",
    "    \n",
    "    if vix_forward > vix_future_trade_day:\n",
    "        total_pl = future_pl - basket_pl\n",
    "        basket_pl = -basket_pl\n",
    "        future_pl = future_pl\n",
    "        comment = 'Buy The future and Sell the basket'\n",
    "    else:\n",
    "        total_pl = basket_pl - future_pl\n",
    "        basket_pl = basket_pl\n",
    "        future_pl = -future_pl\n",
    "        comment = 'Buy the basket and Sell the future'\n",
    "\n",
    "    return future_pl, basket_pl, total_pl, comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pl_per_strike(row):\n",
    "\n",
    "    if row['vix_forward'] > row['vix_future_trade_day']:\n",
    "        pl = (row['future_prices'] - row['mid_quote'])* row['quantity']\n",
    "        ##comment = 'Buy future price sell the basket'\n",
    "    else:\n",
    "        pl =  (row['mid_quote'] - row['future_prices']) * row['quantity']\n",
    "        ##comment = 'Buy basket sell future'\n",
    "    return pl  \n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def redistribute_quantities(df, selected_strikes):\n",
    "    total_quantity_to_redistribute = df[~df.index.isin(selected_strikes.index)]['quantity'].sum()\n",
    "    total_quantity_selected = selected_strikes['quantity'].sum()\n",
    "    proportions = selected_strikes['quantity'] / total_quantity_selected\n",
    "\n",
    "    print(proportions)\n",
    "\n",
    "    selected_strikes['redistributed_quantity'] = proportions * total_quantity_to_redistribute\n",
    "    return selected_strikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def filter_delta_trial(df, bounds = 0.25):\n",
    "    \n",
    "    \n",
    "    # Create an empty DataFrame to store the selected rows\n",
    "    selected_df = pd.DataFrame()\n",
    "    df_calls = df[df['option_type'] == 'C']\n",
    "    df_puts = df[df['option_type'] == 'P']\n",
    "\n",
    "    def select_strikes(df, bounds = 0.1):\n",
    "\n",
    "        # List of absolute delta values to filter by\n",
    "        delta_values = [0.1, 0.25, 0.5]\n",
    "        selected_df_inner = pd.DataFrame()\n",
    "\n",
    "        # Loop over the delta values\n",
    "        for delta in delta_values:\n",
    "            # Calculate the upper and lower bounds for the delta value\n",
    "            lower_bound = delta - delta * bounds\n",
    "            upper_bound = delta + delta * bounds\n",
    "            \n",
    "            # Filter the dataframe for rows where the absolute value of 'delta' is within the bounds\n",
    "            # and the 'strike' value ends with at least one zero\n",
    "            delta_df = df[(df['delta'].abs() >= lower_bound) & (df['delta'].abs() <= upper_bound) & (df['strike'] % 10 == 0)]\n",
    "\n",
    "            # If no rows found, select the row with the delta value closest to the desired delta\n",
    "            if len(delta_df) == 0:\n",
    "                delta_df = df[df['delta'].abs() == df['delta'].abs().sub(delta).abs().min()]\n",
    "\n",
    "            # If there are multiple rows that satisfy the conditions, select the one with the highest quantity (most liquid)\n",
    "            if len(delta_df) > 1:\n",
    "                delta_df = delta_df[delta_df['quantity'] == delta_df['quantity'].max()]\n",
    "\n",
    "            # Append the selected row to the selected dataframe\n",
    "            selected_df_inner = pd.concat([selected_df_inner, delta_df])\n",
    "            \n",
    "        return selected_df_inner\n",
    "\n",
    "    selected_df_calls = select_strikes(df_calls)\n",
    "    selected_df_puts = select_strikes(df_puts)  \n",
    "    selected_df = pd.concat([selected_df_calls, selected_df_puts])\n",
    "      \n",
    "    # Add a new column to store the original quantities\n",
    "    selected_df['original_quantity'] = selected_df['quantity']\n",
    "\n",
    "    # Calculate the total quantity from the original dataframe\n",
    "    total_quantity = df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be removed\n",
    "    removed_quantity = total_quantity - selected_df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be added to each row in the selected DataFrame\n",
    "    selected_df['quantity_added'] = removed_quantity * (selected_df['quantity'] / selected_df['quantity'].sum())\n",
    "\n",
    "    # Add the calculated quantity to the original quantity\n",
    "    selected_df['quantity'] += selected_df['quantity_added']\n",
    "\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def filter_delta_new(df, bounds = 0.1):\n",
    "    display(HTML(df.to_html(index=False, border=0)))\n",
    "    # List of absolute delta values to filter by\n",
    "    delta_values = [0.1, 0.25, 0.5]\n",
    "\n",
    "    # Create an empty DataFrame to store the selected rows\n",
    "    selected_df = pd.DataFrame()\n",
    "    calls_df = df[df['option_type'] == 'call']\n",
    "    puts_df = df[df['option_type'] == 'put']\n",
    "\n",
    "    # Loop over the delta values\n",
    "    for delta in delta_values:\n",
    "        # Calculate the upper and lower bounds for the delta value\n",
    "        lower_bound = delta - delta * bounds\n",
    "        upper_bound = delta + delta * bounds\n",
    "\n",
    "        # Filter the dataframe for rows where the absolute value of 'delta' is within the bounds\n",
    "        # and the 'strike' value ends with at least one zero\n",
    "        delta_df = df[(df['delta'].abs() >= lower_bound) & (df['delta'].abs() <= upper_bound) & (df['strike'] % 10 == 0)]\n",
    "\n",
    "        # If no rows found, select the row with the delta value closest to the desired delta\n",
    "        if len(delta_df) == 0:\n",
    "            delta_df = df[df['delta'].abs() == df['delta'].abs().sub(delta).abs().min()]\n",
    "\n",
    "        # If there are multiple rows that satisfy the conditions, select the one with the highest quantity (most liquid)\n",
    "        if len(delta_df) > 1:\n",
    "            delta_df = delta_df[delta_df['quantity'] == delta_df['quantity'].max()]\n",
    "\n",
    "        # Append the selected row to the selected dataframe\n",
    "        selected_df = pd.concat([selected_df, delta_df])\n",
    "\n",
    "    # Add a new column to store the original quantities\n",
    "    selected_df['original_quantity'] = selected_df['quantity']\n",
    "\n",
    "    # Calculate the total quantity from the original dataframe\n",
    "    total_quantity = df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be removed\n",
    "    removed_quantity = total_quantity - selected_df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be added to each row in the selected DataFrame\n",
    "    selected_df['quantity_added'] = removed_quantity * (selected_df['quantity'] / selected_df['quantity'].sum())\n",
    "\n",
    "    # Add the calculated quantity to the original quantity\n",
    "    selected_df['quantity'] += selected_df['quantity_added']\n",
    "\n",
    "    return selected_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:\n",
      "Duplicates detected\n",
      "                     Trade Date  Weekly  Tenor_Monthly  Tenor_Days  \\\n",
      "37833 2020-02-27 00:00:00-05:00    True            2.0          26   \n",
      "37834 2020-02-27 00:00:00-05:00    True            2.0          26   \n",
      "37848 2020-02-28 00:00:00-05:00    True            2.0          25   \n",
      "37849 2020-02-28 00:00:00-05:00    True            2.0          25   \n",
      "\n",
      "       Tenor_Trade_Days                    Expiry   Open   High    Low  Close  \\\n",
      "37833              19.0 2020-03-25 00:00:00-04:00  24.15  25.35  22.15  24.25   \n",
      "37834              19.0 2020-03-25 00:00:00-04:00  24.15  25.35  22.15  24.25   \n",
      "37848              18.0 2020-03-25 00:00:00-04:00  26.50  27.50  25.65  26.50   \n",
      "37849              18.0 2020-03-25 00:00:00-04:00  26.50  27.50  25.65  26.50   \n",
      "\n",
      "       Settle  Change  Total Volume  EFP  Open Interest  Year  MonthOfYear  \\\n",
      "37833  25.025   3.000            48    0             63  2020            3   \n",
      "37834  25.025   3.000            48    0             63  2020            3   \n",
      "37848  26.100   1.075           112    0            139  2020            3   \n",
      "37849  26.100   1.075           112    0            139  2020            3   \n",
      "\n",
      "            Futures                           File  Expired  \n",
      "37833  H (Mar 2020)  2020-03-25.w_.CFE_VX_2020.csv     True  \n",
      "37834  H (Mar 2020)  2020-03-25.w_.CFE_VX_2020.csv     True  \n",
      "37848  H (Mar 2020)  2020-03-25.w_.CFE_VX_2020.csv     True  \n",
      "37849  H (Mar 2020)  2020-03-25.w_.CFE_VX_2020.csv     True  , cleaning them out\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import vix_utils, logging, asyncio\n",
    "\n",
    "# Specify the directory you want to read from\n",
    "vix_futures,vix_cash=await asyncio.gather(vix_utils.async_load_vix_term_structure(),vix_utils.async_get_vix_index_histories())\n",
    "\n",
    "def calculate_pl(for_pl_directory, consolidated_pl_directory, filename_prefix):\n",
    "    \n",
    "    parent_directory = './result-set/'\n",
    "    # Create a dictionary to hold the dataframes\n",
    "    dataframes = {}\n",
    "\n",
    "    # Iterate over all subdirectories in the parent directory\n",
    "    for trade_date in os.listdir(parent_directory):\n",
    "        # Construct the path to the 'P&L' directory\n",
    "        pl_directory = os.path.join(parent_directory, trade_date, for_pl_directory)\n",
    "        \n",
    "        # Check if the 'P&L' directory exists\n",
    "        if os.path.isdir(pl_directory):\n",
    "            # Get the list of files in the 'P&L' directory\n",
    "            ###files = [f for f in os.listdir(pl_directory) if os.path.isfile(os.path.join(pl_directory, f))]\n",
    "            files = [f for f in os.listdir(pl_directory) if os.path.isfile(os.path.join(pl_directory, f)) and f.startswith(filename_prefix)]\n",
    "\n",
    "            # Sort the files\n",
    "            files.sort()\n",
    "\n",
    "            # Check if there are at least two files\n",
    "            if len(files) >= 2:\n",
    "            # Construct the full file paths\n",
    "                near_file_path = os.path.join(pl_directory, files[0])\n",
    "                next_file_path = os.path.join(pl_directory, files[1])\n",
    "                # Read the files into dataframes\n",
    "                df_near = pd.read_csv(near_file_path)\n",
    "                df_next = pd.read_csv(next_file_path)\n",
    "\n",
    "                vix_forward = df_near['vix_forward'].iloc[0]\n",
    "                sum_value_near = df_near['P&L'].sum()\n",
    "                sum_value_next = df_next['P&L'].sum()\n",
    "                sum_total = sum_value_near + sum_value_next\n",
    "                filtered_df = vix_futures[(vix_futures['Trade Date'] == trade_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "                if not filtered_df.empty:\n",
    "                    vix_futures_on_trade_day = filtered_df['Close'].values[0]\n",
    "                \n",
    "                    year, month, day = trade_date.split('-')\n",
    "                    settlement_date = vix_utils.vix_futures_expiry_date_from_trade_date(int(year), int(month), int(day), 1).strftime('%Y-%m-%d')\n",
    "                    vix_futures_on_settlement_day = vix_futures[(vix_futures['Trade Date'] == settlement_date) & (vix_futures['Tenor_Monthly'] == 1.0)]['Close'].values[0]\n",
    "                    vix_future_delta = vix_futures_on_settlement_day - vix_futures_on_trade_day\n",
    "                    basket_pl = sum_total if vix_forward < vix_futures_on_trade_day else -sum_total\n",
    "                    future_pl = vix_future_delta if vix_futures_on_trade_day < vix_forward  else -vix_future_delta\n",
    "\n",
    "                    # Create a DataFrame\n",
    "                    df_summary = pd.DataFrame({\n",
    "                        'trade_date': [trade_date],\n",
    "                        'Basket-Delta-near': [sum_value_near],\n",
    "                        'Basket-Delta-next': [sum_value_next],\n",
    "                        'Basket-Delta-total': [sum_total],\n",
    "                        'vix-forward': [vix_forward],\n",
    "                        'vix-futures-on-trade_day': [vix_futures_on_trade_day],\n",
    "                        'vix-futures-on-settlement_day': [vix_futures_on_settlement_day],\n",
    "                        'Future-Delta' : [vix_future_delta],\n",
    "                        'Basket-P&L': basket_pl,\n",
    "                        'Future-P&L': future_pl,\n",
    "                        'Total-P&L': basket_pl + future_pl     \n",
    "                    })\n",
    "\n",
    "                    # Print the DataFrame\n",
    "                    print(df_summary)\n",
    "                    ###df_summary.to_csv(os.path.join(pl_directory, f'option_basket_P&L_{trade_date}.csv'), index=False)\n",
    "                    df_summary.to_csv(os.path.join(consolidated_pl_directory, f'option_basket_P&L_{trade_date}.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pl_dir:  ./result-set/2023-02-07\\P&L\n",
      "pl_dir:  ./result-set/2023-02-15\\P&L\n",
      "pl_dir:  ./result-set/P&L-across-days\\P&L\n",
      "No files found with the pattern dataset_*.csv.\n",
      "No files found with the pattern filtered_delta_strikes_dataset_*.csv.\n"
     ]
    }
   ],
   "source": [
    "def chain_of_responsibility(delta_filter):\n",
    "    calculate_greeks_add_future_prices()\n",
    "    pl_directory = 'P&L'\n",
    "    consolidated_pl_directory = './result-set/P&L-across-days/'\n",
    "    #calculate_pl(pl_directory, consolidated_pl_directory, filename_prefix='dataset_')\n",
    "    #calculate_pl(pl_directory, consolidated_pl_directory, filename_prefix='filtered_delta_strikes_')\n",
    "\n",
    "delta_filter = 0.24\n",
    "chain_of_responsibility(delta_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Specify the directory you want to read from\n",
    "directory = './result-set/P&L-across-days/'\n",
    "\n",
    "# Create a list to hold all the dataframes\n",
    "dfs = []\n",
    "\n",
    "# Iterate over all files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):  # Assuming the files are CSVs\n",
    "        # Read the file into a dataframe\n",
    "        df = pd.read_csv(os.path.join(directory, filename))\n",
    "\n",
    "        # Add the dataframe to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "# Concatenate all dataframes in the list\n",
    "consolidated_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Save the consolidated dataframe to a new CSV file\n",
    "consolidated_df.to_csv(f'{directory}/consolidated.csv', index=False)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a Pandas Excel writer using XlsxWriter as the engine.\n",
    "with pd.ExcelWriter(f'{directory}/pandas_conditional.xlsx', engine='xlsxwriter') as writer:\n",
    "    # Convert the dataframe to an XlsxWriter Excel object.\n",
    "    consolidated_df.to_excel(writer, sheet_name='Sheet1', index=False)\n",
    "\n",
    "    # Get the xlsxwriter workbook and worksheet objects.\n",
    "    workbook  = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "\n",
    "    # Define a format for the red color. \n",
    "    red_format = workbook.add_format({'bg_color': '#FF0000'})\n",
    "\n",
    "    # Apply a conditional format to the cells in the 'Total-P&L' column.\n",
    "    worksheet.conditional_format('A1:Z1000', {'type': 'formula',\n",
    "                                              'criteria': '=$K1<0',\n",
    "                                              'format': red_format})\n",
    "    # Count the number of positive and negative 'Total-P&L' values.\n",
    "    positive_count = (consolidated_df['Total-P&L'] > 0).sum()\n",
    "    negative_count = (consolidated_df['Total-P&L'] < 0).sum()\n",
    "\n",
    "    # Create a new DataFrame to hold the counts.\n",
    "    counts_df = pd.DataFrame({\n",
    "        'Condition': ['Total-P&L > 0', 'Total-P&L < 0'],\n",
    "        'Count': [positive_count, negative_count]\n",
    "    })\n",
    "\n",
    "    # Write the counts DataFrame to a new sheet in the Excel file.\n",
    "    counts_df.to_excel(writer, sheet_name='Counts', index=False)\n",
    "\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_near =pd.read_csv('./result-set/2023-02-07/P&L/dataset_20230317.csv')\n",
    "df_next =pd.read_csv('./result-set/2023-02-07/P&L/dataset_20230324.csv')\n",
    "df_25_delta_near = pd.read_csv('./result-set/2023-02-07/P&L/filterd_delta_strikes_dataset_20230317.csv')\n",
    "df_25_delta_next = pd.read_csv('./result-set/2023-02-07/P&L/filterd_delta_strikes_dataset_20230324.csv')\n",
    "\n",
    "\n",
    "df_combined_near = df_25_delta_near.merge(df_near[['strike', 'quantity','future_prices']], on='strike', how='left')\n",
    "df_combined_near.rename(columns={'quantity_y': 'old_quantity', 'quantity_x': 'quantity'}, inplace=True)\n",
    "df_combined_near = df_combined_near[['strike', 'option_type', 'per_strike_constants', 'mid_quote', 'future_prices','old_quantity','quantity','vix_forward', 'Implied Vol','delta']].copy()\n",
    "df_combined_near['Term'] = 'Near'\n",
    "\n",
    "df_combined_next = df_25_delta_next.merge(df_next[['strike', 'quantity', 'future_prices']], on='strike', how='left')\n",
    "df_combined_next.rename(columns={'quantity_y': 'old_quantity', 'quantity_x': 'quantity'}, inplace=True)\n",
    "df_combined_next = df_combined_next[['strike', 'option_type', 'per_strike_constants','mid_quote', 'future_prices', 'old_quantity','quantity','vix_forward', 'Implied Vol','delta']].copy()\n",
    "df_combined_next['Term'] = 'Next'\n",
    "\n",
    "df_combined_final = pd.concat([df_combined_near, df_combined_next])\n",
    "\n",
    "df_combined_near.to_csv('./result-set/2023-02-07/P&L/Final/filterd_delta_strikes_dataset_20230317.csv', index=False)\n",
    "df_combined_next.to_csv('./result-set/2023-02-07/P&L/Final/filterd_delta_strikes_dataset_20230324.csv', index=False)\n",
    "df_combined_final.to_csv('./result-set/2023-02-07/P&L/Final/filterd_delta_strikes_dataset.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def filter_delta_trial_latest(df, bounds = 0.25):\n",
    "    # Create an empty DataFrame to store the selected rows\n",
    "    selected_df = pd.DataFrame()\n",
    "    df_calls = df[df['option_type'] == 'C']\n",
    "    df_puts = df[df['option_type'] == 'P']\n",
    "\n",
    "    delta_series = pd.Series(delta)               \n",
    "\n",
    "    def select_strike(df, delta, bound):\n",
    "    # Calculate the lower and upper bounds\n",
    "    lower_bound = delta - bound\n",
    "    upper_bound = delta + bound\n",
    "\n",
    "    # Select rows where the absolute delta is within the bounds\n",
    "    delta_df = df[(df['delta'].abs() >= lower_bound) & (df['delta'].abs() <= upper_bound)]\n",
    "\n",
    "    # If no rows found within bounds, select the row with the delta value closest to the desired delta\n",
    "    if len(delta_df) == 0:\n",
    "        delta_df = df[df['delta'].abs() == df['delta'].abs().sub(delta).abs().min()]\n",
    "\n",
    "    # Try to select the row with the strike that ends with a zero\n",
    "    delta_df_zero_strike = delta_df[delta_df['strike'] % 10 == 0]\n",
    "\n",
    "    # If there are multiple rows that satisfy the conditions, select the one with the highest quantity (most liquid)\n",
    "    if len(delta_df_zero_strike) > 1:\n",
    "        delta_df_zero_strike = delta_df_zero_strike[delta_df_zero_strike['quantity'] == delta_df_zero_strike['quantity'].max()]\n",
    "    elif len(delta_df_zero_strike) == 0 and len(delta_df) > 1:\n",
    "        delta_df = delta_df[delta_df['quantity'] == delta_df['quantity'].max()]\n",
    "\n",
    "    # Return the selected row\n",
    "    return delta_df_zero_strike if len(delta_df_zero_strike) > 0 else delta_df\n",
    "\n",
    "    selected_strikes_calls = delta_series.apply(lambda d: select_strike(df_calls, d, bound))\n",
    "    selected_strikes_puts = delta_series.apply(lambda d: select_strike(df_puts, d, bound))\n",
    "    \n",
    "    selected_df_calls = pd.concat(selected_strikes_calls.tolist())\n",
    "    selected_df_puts = pd.concat(selected_strikes_puts.tolist())\n",
    "\n",
    "    selected_df = pd.concat([selected_df_calls, selected_df_puts])\n",
    "      \n",
    "    # Add a new column to store the original quantities\n",
    "    selected_df['original_quantity'] = selected_df['quantity']\n",
    "\n",
    "    # Calculate the total quantity from the original dataframe\n",
    "    total_quantity = df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be removed\n",
    "    removed_quantity = total_quantity - selected_df['quantity'].sum()\n",
    "\n",
    "    # Calculate the quantity to be added to each row in the selected DataFrame\n",
    "    selected_df['quantity_added'] = removed_quantity * (selected_df['quantity'] / selected_df['quantity'].sum())\n",
    "\n",
    "    # Add the calculated quantity to the original quantity\n",
    "    selected_df['quantity'] += selected_df['quantity_added']\n",
    "\n",
    "    return selected_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
