{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, HTML\n",
    "from scipy import interpolate\n",
    "from yahoo_fin import options as op, stock_info as si\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a file handler\n",
    "handler = logging.FileHandler('error_log.txt')\n",
    "handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Global flag for controlling print statements\n",
    "enable_print = False\n",
    "\n",
    "def custom_print(*args, **kwargs):\n",
    "    global enable_print\n",
    "    if enable_print:\n",
    "        print(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4783.830078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\yahoo_fin\\stock_info.py:580: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.close[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yahoo_fin import options as op, stock_info as si\n",
    "s = si.get_live_price(\"^GSPC\")\n",
    "print(s)\n",
    "l = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "l[:-2]\n",
    "l[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Implied Volatility: 0.2615502045962956\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "from scipy.optimize import brentq\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameters\n",
    "underlyingPrice = 4567.7998046875\n",
    "strikePrice = 1200\n",
    "interestRate = 0.01\n",
    "daysToExpiration = 2\n",
    "optionPrice = 0.025    \n",
    "option_type = 'P'\n",
    "\n",
    "# Define the Black-Scholes function\n",
    "def black_scholes(sigma):\n",
    "    d1 = (np.log(underlyingPrice / strikePrice) + (interestRate + 0.5 * sigma**2) * daysToExpiration) / (sigma * np.sqrt(daysToExpiration))\n",
    "    d2 = d1 - sigma * np.sqrt(daysToExpiration)\n",
    "    return strikePrice * np.exp(-interestRate * daysToExpiration) * norm.cdf(-d2) - underlyingPrice * norm.cdf(-d1)\n",
    "\n",
    "# Define the function to find the root of\n",
    "def root_function(sigma):\n",
    "    return black_scholes(sigma) - optionPrice\n",
    "\n",
    "# Use Brent's method to find the implied volatility\n",
    "implied_volatility, info = brentq(root_function, 0.0001, 1, full_output=True)\n",
    "\n",
    "if info.converged:\n",
    "    print(f\"Implied Volatility: {implied_volatility}\")\n",
    "else:\n",
    "    print(\"The method did not converge to a solution.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility I.V\n",
      "3569.846137133341 0.015401474274906068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\yahoo_fin\\stock_info.py:580: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.close[-1]\n"
     ]
    }
   ],
   "source": [
    "import mibian\n",
    "\n",
    "# Define the parameters\n",
    "underlyingPrice = si.get_live_price(\"^GSPC\")\n",
    "strikePrice = 1200\n",
    "interestRate = 0.01\n",
    "daysToExpiration = 2\n",
    "optionPrice = 0.025 #3360.5 \t\n",
    "option_type = 'None'\n",
    "volatility = 492.1875 #0.00010 \n",
    "\n",
    "# Create an instance of the BS class with the parameters\n",
    "if option_type == 'C':\n",
    "    print('Call I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], callPrice=optionPrice)\n",
    "elif option_type == 'P':\n",
    "    print('Put I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], putPrice=optionPrice)\n",
    "elif volatility != None:\n",
    "    print('Volatility I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], volatility=volatility)    \n",
    "    print(bs.callPrice, bs.putPrice)\n",
    "else:\n",
    "    print('Invalid option type')    \n",
    "\n",
    "# Print the implied volatility\n",
    "if volatility == None:\n",
    "    print(bs.impliedVolatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 15840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\yahoo_fin\\stock_info.py:580: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.close[-1]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cubic_spline_risk_free_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 53\u001b[0m\n\u001b[0;32m     51\u001b[0m spot \u001b[38;5;241m=\u001b[39m si\u001b[38;5;241m.\u001b[39mget_live_price(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m^GSPC\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m#Rate \u001b[39;00m\n\u001b[1;32m---> 53\u001b[0m r, rate_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mcubic_spline_risk_free_rate\u001b[49m([forward_minutes, forward_minutes]))\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(r, rate_)\n\u001b[0;32m     55\u001b[0m \u001b[38;5;66;03m#r = 0.01\u001b[39;00m\n\u001b[0;32m     56\u001b[0m  \n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m#Get data frame\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cubic_spline_risk_free_rate' is not defined"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import mibian\n",
    "from yahoo_fin import options as op, stock_info as si\n",
    "from IPython.display import display, HTML\n",
    "from dataclasses import dataclass, field\n",
    "  \n",
    "@dataclass\n",
    "class BSParams:\n",
    "    underlyingPrice: float = field(default=0.0)\n",
    "    strikePrice: float = field(default=0.0)\n",
    "    interestRate: float = field(default=0.0)\n",
    "    daysToExpiration: int = field(default=0)\n",
    "    price: float = field(default=0.0)\n",
    "    option_type: str = field(default='C')\n",
    "    volatility: float = field(default=0.0)\n",
    "\n",
    "\n",
    "def calculate_call_iv(bs_params, price):\n",
    "    return mibian.BS(bs_params, callPrice=price).impliedVolatility\n",
    "    #return mibian.BS(params[:-2], callPrice=params[-2]).impliedVolatility\n",
    "\n",
    "def calculate_put_iv(bs_params, price):\n",
    "    return mibian.BS(bs_params, putPrice=price).impliedVolatility\n",
    "    #return mibian.BS(params[:-2], putPrice=params[-2]).impliedVolatility\n",
    "\n",
    "def calculate_iv(params: BSParams):\n",
    "    bs_params = [params.underlyingPrice, params.strikePrice, params.interestRate, params.daysToExpiration]\n",
    "    # Use the option type to select the function: 0 for call, 1 for put\n",
    "    return [calculate_call_iv, calculate_put_iv][params.option_type == 'P'](bs_params, params.price)\n",
    "\n",
    "def calculate_price(params: BSParams):\n",
    "    bs_params = [params.underlyingPrice, params.strikePrice, params.interestRate, params.daysToExpiration]\n",
    "    # Use the option type to select the function: 0 for call, 1 for put\n",
    "    c = mibian.BS(bs_params, volatility=params.volatility)\n",
    "    return c.callPrice, c.putPrice\n",
    "\n",
    "# Time Delta\n",
    "###december_1 = datetime.date(today.year, 12, 1)\n",
    "# Get today's date\n",
    "##today = datetime.date.today() - datetime.timedelta(days=0)\n",
    "# Calculate the number of days to 1st December\n",
    "# t_december_1 = (december_1 - today).days\n",
    "# print(t_december_1)\n",
    "# print(december_1, today)\n",
    "\n",
    "# Forward day\n",
    "forward_days = datetime.timedelta(days= 11).days\n",
    "forward_minutes = forward_days * 24 * 60\n",
    "print(forward_days, forward_minutes)\n",
    "#Spot\n",
    "spot = si.get_live_price(\"^GSPC\")\n",
    "#Rate \n",
    "r, rate_ = np.array(cubic_spline_risk_free_rate([forward_minutes, forward_minutes]))/100\n",
    "print(r, rate_)\n",
    "#r = 0.01\n",
    " \n",
    "#Get data frame\n",
    "df_dec1 = pd.read_csv('c:/Python311/Lib/site-packages/yahoo_fin/dataset/28Nov/SPXW US -01-12-2023_data-Copy.csv')\n",
    "\n",
    "\n",
    "# Apply the function to each row of the DataFrame\n",
    "df_dec1['IV'] = df_dec1.apply(lambda row: calculate_iv(BSParams(underlyingPrice= spot, strikePrice= row['strike'], interestRate= r, \n",
    "                                 daysToExpiration = forward_days, price = row['price'], option_type = row['option_type'])), axis=1)\n",
    "\n",
    "df_dec1['calc_price_list'] = df_dec1.apply(lambda row: calculate_price(BSParams(underlyingPrice= spot, strikePrice= row['strike'], interestRate= r,\n",
    "                                            daysToExpiration =  forward_days, volatility = row['IV'])), axis=1)\n",
    "df_dec1['concatenated'] = df_dec1['calc_price_list'].apply(lambda x: ':'.join(map(str, x)))\n",
    "display(HTML(df_dec1.to_html(index=False, border=0)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'py_vollib_vectorized'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Python311\\Lib\\site-packages\\yahoo_fin\\vix_modelling.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python311/Lib/site-packages/yahoo_fin/vix_modelling.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python311/Lib/site-packages/yahoo_fin/vix_modelling.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Python311/Lib/site-packages/yahoo_fin/vix_modelling.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpy_vollib_vectorized\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mblack_scholes\u001b[39;00m \u001b[39mimport\u001b[39;00m implied_volatility\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python311/Lib/site-packages/yahoo_fin/vix_modelling.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Parameters\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Python311/Lib/site-packages/yahoo_fin/vix_modelling.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m  \u001b[39m# Underlying price\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'py_vollib_vectorized'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from py_vollib_vectorized.black_scholes import implied_volatility\n",
    "\n",
    "# Parameters\n",
    "s = 100  # Underlying price\n",
    "t = 0.5  # Time to expiration\n",
    "r = 0.01  # Risk-free rate\n",
    "\n",
    "# Assuming df is your DataFrame and it has columns 'option_prices', 'flag', 's', 'k'\n",
    "df = pd.DataFrame({\n",
    "    'option_prices': [11.70, 7.95, 5.00, 3.05, 1.90],\n",
    "    'flag': ['c', 'c', 'c', 'c', 'c'],\n",
    "    's': [100, 100, 100, 100, 100],\n",
    "    'k': [90, 95, 100, 105, 110]\n",
    "})\n",
    "\n",
    "\n",
    "def calculate_iv(row):\n",
    "    return implied_volatility(row['option_prices'], row['flag'], row['s'], row['k'], t, r)\n",
    "\n",
    "\n",
    "df['implied_volatility'] = df.apply(calculate_iv, axis=1)\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py_vollib_vectorizedNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.1.2 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached py_vollib_vectorized-0.1.1-py3-none-any.whl (30 kB)\n",
      "Collecting py-vollib>=1.0.1 (from py_vollib_vectorized)\n",
      "  Using cached py_vollib-1.0.1-py3-none-any.whl\n",
      "Requirement already satisfied: numba>=0.51.0 in c:\\python311\\lib\\site-packages (from py_vollib_vectorized) (0.58.1)\n",
      "Requirement already satisfied: py-lets-be-rational in c:\\python311\\lib\\site-packages (from py_vollib_vectorized) (1.0.1)\n",
      "Requirement already satisfied: numpy in c:\\python311\\lib\\site-packages (from py_vollib_vectorized) (1.26.0)\n",
      "Requirement already satisfied: pandas in c:\\python311\\lib\\site-packages (from py_vollib_vectorized) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\python311\\lib\\site-packages (from py_vollib_vectorized) (1.11.2)\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in c:\\python311\\lib\\site-packages (from numba>=0.51.0->py_vollib_vectorized) (0.41.1)\n",
      "Requirement already satisfied: simplejson in c:\\python311\\lib\\site-packages (from py-vollib>=1.0.1->py_vollib_vectorized) (3.19.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas->py_vollib_vectorized) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python311\\lib\\site-packages (from pandas->py_vollib_vectorized) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\python311\\lib\\site-packages (from pandas->py_vollib_vectorized) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas->py_vollib_vectorized) (1.16.0)\n",
      "Installing collected packages: py-vollib, py_vollib_vectorized\n",
      "Successfully installed py-vollib-1.0.1 py_vollib_vectorized-0.1.1\n"
     ]
    }
   ],
   "source": [
    "%pip install py_vollib_vectorized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to expiration:  2023-02-10 00:00:00-05:00 2023-02-17 00:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def chicago_eod_four_PM(eod, near_term=True):\n",
    "    # Create a datetime object for 4 PM on November 10\n",
    "    # replace 2023 with the correct year\n",
    "    # 14.17 as of 11th Nov 2020\n",
    "    four_pm = datetime.datetime(\n",
    "        eod['year'], eod['month'], eod['day'], eod['hour'], eod['minute'], 0)  # 10th Nov 2023\n",
    "\n",
    "    # Convert the datetime object to Eastern Time\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    four_pm_et = eastern.localize(four_pm)\n",
    "    custom_print(\"four_pm_et: \", four_pm_et)\n",
    "\n",
    "    tomorrow = datetime.datetime(\n",
    "        four_pm_et.year, four_pm_et.month, four_pm_et.day, tzinfo=four_pm_et.tzinfo) + datetime.timedelta(1)\n",
    "    days = [four_pm_et + datetime.timedelta(index) for index in range(24, 38)]\n",
    "\n",
    "    friday = next(day for day in days if day.weekday() == 4)\n",
    "    next_term = -1 if near_term == True else 6\n",
    "    days_to_expiration = (friday - four_pm_et).days + next_term\n",
    "    expiration_day = datetime.datetime(\n",
    "        four_pm_et.year, four_pm_et.month, four_pm_et.day,\n",
    "        tzinfo=four_pm_et.tzinfo) + datetime.timedelta(days_to_expiration + 1)\n",
    "    custom_print(\"days to expiration: \", days_to_expiration)\n",
    "    custom_print(\"friday: \", friday)\n",
    "    custom_print(\"expiration day: \", expiration_day)\n",
    "    custom_print(\"expiration day - calculation day: \", expiration_day - four_pm_et)\n",
    "\n",
    "    # minutes_to_settlement = 570 if friday.day in range(     #friday.day to expiration_day.day will cover near and next term\n",
    "    #     15, 22) and friday.weekday() == 4 else 960\n",
    "\n",
    "    minutes_to_settlement = 570 if expiration_day.day in range(\n",
    "        15, 22) and friday.weekday() == 4 else 960\n",
    "\n",
    "    minutes_to_midnight_today = (tomorrow - four_pm_et).seconds // 60\n",
    "    minutes_to_expiration = days_to_expiration * 24 * 60\n",
    "\n",
    "    custom_print(minutes_to_midnight_today, minutes_to_settlement, minutes_to_expiration)\n",
    "    time_to_expiration = (minutes_to_midnight_today +\n",
    "                          minutes_to_settlement + minutes_to_expiration)\n",
    "\n",
    "    # time_to_expiration = (minutes_to_midnight_today +\n",
    "    #                       minutes_to_settlement + minutes_to_expiration) / 525600\n",
    "\n",
    "    return (time_to_expiration, expiration_day, four_pm_et, days_to_expiration)\n",
    "\n",
    "\n",
    "yesterday = datetime.datetime(2023, 1, 16) - datetime.timedelta(days=0)\n",
    "eod = {\n",
    "    \"year\": yesterday.year,\n",
    "    \"month\": yesterday.month,\n",
    "    \"day\": yesterday.day,\n",
    "    \"hour\": 16,\n",
    "    \"minute\": 15,\n",
    "    \"second\": 0\n",
    "}\n",
    "print(\"Time to expiration: \", chicago_eod_four_PM(\n",
    "    eod, True)[1], chicago_eod_four_PM(eod, False)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[43804,\n",
       "  87608,\n",
       "  131412,\n",
       "  175216,\n",
       "  262824,\n",
       "  525600,\n",
       "  1051200,\n",
       "  1576800,\n",
       "  2628000,\n",
       "  3679200,\n",
       "  5256000,\n",
       "  10512000,\n",
       "  15768000],\n",
       " ['4.58',\n",
       "  '4.64',\n",
       "  '4.70',\n",
       "  '4.74',\n",
       "  '4.80',\n",
       "  '4.68',\n",
       "  '4.21',\n",
       "  '3.90',\n",
       "  '3.63',\n",
       "  '3.59',\n",
       "  '3.52',\n",
       "  '3.78',\n",
       "  '3.65']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale(days = 0):\n",
    "    \"\"\"\n",
    "    Retrieves and formats the US Treasury yield curve.\n",
    "    No arguments.\n",
    "    \"\"\"\n",
    "    calctime = datetime.datetime.now() - datetime.timedelta(days)\n",
    "    year = calctime.year\n",
    "    month = calctime.month\n",
    "    custom_print(year, month)\n",
    "    # year = datetime.datetime.now().year\n",
    "    # month = datetime.datetime.now().month\n",
    "    url = f\"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/pages/xmlview?data=daily_treasury_yield_curve&field_tdr_date_value_month={year}{month:02d}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    #print(json.dumps(response.content.decode(), indent=4))\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    temp_us_treasury_dict = {}\n",
    "    us_treasury_dict = {}\n",
    "\n",
    "    for elt in root.iter():\n",
    "        temp_us_treasury_dict[elt.tag[-8:]] = elt.text\n",
    "\n",
    "    for key in temp_us_treasury_dict.keys():\n",
    "        if (key.find(\"MONTH\") + key.find(\"YEAR\") + key.find(\"DATE\") != -3):\n",
    "            us_treasury_dict[re.sub(r'.*_', '', key)\n",
    "                             ] = temp_us_treasury_dict[key]\n",
    "\n",
    "    # Based on the average number of day in a month: 30.42\n",
    "    minutes_in_a_month = 43804\n",
    "    minutes_in_a_year = 525600\n",
    "\n",
    "    # minute axis\n",
    "    #x = [int(key[:-5])*minutes_in_a_month if \"MONTH\" in key else int(key[:-4])*minutes_in_a_year if \"YEAR\" in key else None for key in us_treasury_dict.keys()]\n",
    "    x = [int(key[:-5])*minutes_in_a_month if \"MONTH\" in key else int(key[:-4]) *\n",
    "         minutes_in_a_year if \"YEAR\" in key else None for key in us_treasury_dict.keys() if \"MONTH\" in key or \"YEAR\" in key]\n",
    "\n",
    "    # yield axis\n",
    "    y = [us_treasury_dict[key]\n",
    "         for key in us_treasury_dict.keys() if \"MONTH\" in key or \"YEAR\" in key]\n",
    "    custom_print(\"Yield curve:\", us_treasury_dict)\n",
    "    custom_print(\"Yield curve in minutes scale:\", dict(zip(x, y)))\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "r = scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale(days = 365)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "\n",
    "def cubic_spline_risk_free_rate(minutes_to_expiration, days = 0):\n",
    "    \"\"\"\n",
    "    Estimates the risk free rate (based on the US treasury yield) at a specific time to expiration\n",
    "    :param <time_to_expiration>: integer ; time to expiration in day or minutes \n",
    "    :param <minute_data>: boolean ; indicates if the argument <time_to_expiration> is in minutes or days\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the tenors and corresponding yields from the US Treasury yield curve\n",
    "    yc = scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale()\n",
    "    tenors = yc[0]\n",
    "    rates = yc[1]\n",
    "\n",
    "    # Sort the data by tenor\n",
    "    sorted_indices = np.argsort(tenors)\n",
    "    # print(sorted_indices)\n",
    "    #tenors_sorted = tenors[sorted_indices.tolist()]\n",
    "    #rates_sorted = rates[sorted_indices.tolist()]\n",
    "\n",
    "    tenors_sorted = [tenors[i] for i in sorted_indices]\n",
    "    rates_sorted = [rates[i] for i in sorted_indices]\n",
    "\n",
    "    # print(tenors_sorted)\n",
    "    # print(rates_sorted)\n",
    "\n",
    "    # Create a cubic spline interpolator\n",
    "    cs = CubicSpline(tenors_sorted, rates_sorted,\n",
    "                     extrapolate=True)  # Allow extrapolation\n",
    "\n",
    "    # Specify expiration dates of near-term and next-term options (replace with actual dates)\n",
    "    #near_term_expiration = date(2023, 12, 31)\n",
    "    #next_term_expiration = date(2024, 3, 31)\n",
    "\n",
    "    # Calculate time remaining until expiration in years\n",
    "    #today = date.today()\n",
    "    #time_to_near_term = (near_term_expiration - today).days / 365\n",
    "    #time_to_next_term = (next_term_expiration - today).days / 365\n",
    "\n",
    "    time_to_near_term = minutes_to_expiration[0]\n",
    "    time_to_next_term = minutes_to_expiration[1]\n",
    "    #time_to_near_term = 34,484\n",
    "    #time_to_next_term = 44,954\n",
    "\n",
    "    # Calculate interpolated/extrapolated yields using cubic spline\n",
    "    yield_R1 = cs(time_to_near_term)\n",
    "    yield_R2 = cs(time_to_next_term)\n",
    "    # print(f\"R1 (BEY) for {time_to_near_term} minutes: {yield_R1}\")\n",
    "    # print(f\"R2 (BEY) for {time_to_next_term} minutes: {yield_R2}\")\n",
    "\n",
    "    # Convert BEY to APY using the correct formula\n",
    "    APY_R1 = ((1 + yield_R1 / 2) ** 2) - 1\n",
    "    APY_R2 = ((1 + yield_R2 / 2) ** 2) - 1\n",
    "\n",
    "    r_near = np.log(1 + APY_R1)\n",
    "    r_next = np.log(1 + APY_R2)\n",
    "\n",
    "    # print(f\"R1 (APY) for {time_to_near_term} minutes: {APY_R1}\")\n",
    "    # print(f\"R2 (APY) for {time_to_next_term} minutes: {APY_R2}\")\n",
    "\n",
    "    # print(f\"R1 (ln(APY+1)) for {time_to_near_term} minutes: {r_near}\")\n",
    "    # print(f\"R2 (ln(APY+1)) for {time_to_next_term} minutes: {r_next}\")\n",
    "\n",
    "    # return [APY_R1, APY_R2]\n",
    "    # return [r_near, r_next]\n",
    "    return [yield_R1, yield_R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_strike_diff(df):\n",
    "    # Create a new column 'strike_prev' that contains the previous 'strike' values\n",
    "    df['strike_prev'] = df['strike'].shift(-1)\n",
    "\n",
    "    # Create a new column 'strike_next' that contains the next 'strike' values\n",
    "    df['strike_next'] = df['strike'].shift(1)\n",
    "\n",
    "    # Create a new column 'strike_diff' that contains the differences between 'strike_next' and 'strike_prev'\n",
    "    df['strike_diff'] = (df['strike_prev'] - df['strike_next'])/2\n",
    "\n",
    "    # For the first and last 'strike', keep the original 'strike' values\n",
    "    # df.loc[0, 'strike_diff'] = df.loc[1, 'strike'] - df.loc[0, 'strike']\n",
    "    df.iloc[0, df.columns.get_loc('strike_diff')] = df.iloc[1, df.columns.get_loc('strike')] - \\\n",
    "        df.iloc[0, df.columns.get_loc('strike')]\n",
    "\n",
    "    df.iloc[-1, df.columns.get_loc('strike_diff')] = df.iloc[-1, df.columns.get_loc('strike')] -\\\n",
    "        df.iloc[-2, df.columns.get_loc('strike')]\n",
    "    # df.loc[df.index[-1], 'strike_diff'] = df.loc[df.index[-1],\n",
    "    #                                              'strike'] - df.loc[df.index[-2], 'strike']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_strikes(df, option_type = None):\n",
    "    # Create new columns that contain the 'bid' values of the preceding and following rows\n",
    "    df['bid_prev1'] = df['bid'].shift(1)\n",
    "    df['bid_next1'] = df['bid'].shift(-1)\n",
    "\n",
    "    # For 'Call' options, find the first index where 'bid' and 'bid_next1' are 0\n",
    "    if option_type == 'Call' or df['option_type'].isin(['C', 'Call']).any():\n",
    "        try:\n",
    "            index_to_drop = df[(df['bid'] == 0) & (\n",
    "                df['bid_next1'] == 0)].index[0]\n",
    "            # Drop all rows from 'index_to_drop' to the end of the DataFrame\n",
    "            df = df.loc[:index_to_drop-1]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        except KeyError as e:\n",
    "        # Log the state of the DataFrame when the error occurs\n",
    "            logger.info(f\"Error: {e}\")\n",
    "            logger.info(f\"DataFrame state: {df.to_string()}\")\n",
    "            logger.info(f\"index_to_drop: {index_to_drop}\")\n",
    "            logger.info(f\"last_index: {last_index}\")\n",
    "            #print(f\"Error: {e}\")\n",
    "            #print(f\"DataFrame state: {df.to_string()}\")\n",
    "            print(f\"index_to_drop: {index_to_drop}\")\n",
    "            print(f\"last_index: {last_index}\")\n",
    "\n",
    "    # For 'Put' options, find the first index where 'bid' and 'bid_prev1' are 0\n",
    "    elif option_type == 'Put' or df['option_type'].isin(['P', 'Put']).any():\n",
    "        try:\n",
    "            index_to_drop = df[(df['bid'] == 0) & (\n",
    "                df['bid_prev1'] == 0)].index[0]\n",
    "            # Drop all rows from the start of the DataFrame to 'index_to_drop'\n",
    "            last_index = df.index[-1]\n",
    "            if index_to_drop < last_index:\n",
    "                df = df.loc[index_to_drop+1:]\n",
    "            else:\n",
    "                df = df.loc[:last_index]\n",
    "            #df = df.loc[index_to_drop+1:]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        except KeyError as e:\n",
    "        # Log the state of the DataFrame when the error occurs\n",
    "            logger.info(f\"Error: {e}\")\n",
    "            logger.info(f\"DataFrame state: {df.to_string()}\")\n",
    "            logger.info(f\"index_to_drop: {index_to_drop}\")\n",
    "            logger.info(f\"last_index: {last_index}\")\n",
    "            #print(f\"Error: {e}\")\n",
    "            #print(f\"DataFrame state: {df.to_string()}\")\n",
    "            print(f\"index_to_drop: {index_to_drop}\")\n",
    "            print(f\"last_index: {last_index}\")\n",
    "\n",
    "    # Drop the 'bid_prev1' and 'bid_next1' columns\n",
    "    df = df.drop(columns=['bid_prev1', 'bid_next1'])\n",
    "\n",
    "    # remove any row that has zeor bid\n",
    "    df = df[df['bid'] != 0]\n",
    "\n",
    "    #display(HTML(df.to_html(index=False, border=0)))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_atm(min_diff_strike, df_calls, df_puts, activation, near_term):\n",
    "    \"\"\"\n",
    "    Calculate forward VIX by extraploating minimum strike price...\n",
    "    \"\"\"\n",
    "    df_calls_copy = df_calls.copy().set_index('strike', inplace=False)\n",
    "    df_puts_copy = df_puts.copy().set_index('strike', inplace=False)\n",
    "\n",
    "    forward = min_diff_strike + \\\n",
    "        activation * (df_calls.loc[df_calls['strike'] == min_diff_strike, 'mid-quote'].values[0] -\n",
    "                      df_puts.loc[df_puts['strike'] == min_diff_strike, 'mid-quote'].values[0])\n",
    "\n",
    "    print(\"Forward: \", forward)\n",
    "    common_strikes = df_calls_copy.index.intersection(df_puts_copy.index)\n",
    "\n",
    "    lower_strikes = common_strikes[common_strikes < forward]\n",
    "    atm_strike = lower_strikes.max()\n",
    "\n",
    "    #atm_strike = df_calls[df_calls['strike'] < f_near]['strike'].max()\n",
    "\n",
    "    row_calls = df_calls.loc[df_calls['strike']\n",
    "                             == atm_strike].reset_index(drop=True)\n",
    "    row_puts = df_puts.loc[df_puts['strike']\n",
    "                           == atm_strike].reset_index(drop=True)\n",
    "    average_values = (row_calls[['mid-quote', 'bid', 'ask', 'px_last']] +\n",
    "                      row_puts[['mid-quote', 'bid', 'ask', 'px_last']]) / 2\n",
    "    average_values['strike'] = atm_strike\n",
    "    average_values['option_type'] = 'ATM Avg Put/Call'\n",
    "    atm_df = average_values[['strike', 'bid', 'ask',\n",
    "                             'option_type', 'px_last', 'mid-quote']]\n",
    "\n",
    "    display(HTML(atm_df.to_html(index=False, border=0)))\n",
    "    return forward, atm_df, atm_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_diff_strike(df_calls, df_puts):\n",
    "    # Set the strike price as the index in both dataframes\n",
    "    df_calls_copy = df_calls.copy()\n",
    "    df_puts_copy = df_puts.copy()\n",
    "\n",
    "    df_calls_copy.set_index('strike', inplace=True)\n",
    "    df_puts_copy.set_index('strike', inplace=True)\n",
    "\n",
    "    # Calculate the difference between the mid-quote values\n",
    "\n",
    "    mid_quote_diff = (df_calls_copy['mid-quote'] -\n",
    "                      df_puts_copy['mid-quote']).abs()\n",
    "\n",
    "    # Find the strike price with the minimum difference\n",
    "    try:\n",
    "        min_diff_strike = mid_quote_diff.idxmin()\n",
    "    except ValueError:\n",
    "        logger.error(\"Attempted to get argmin of an empty sequence.\")\n",
    "        logger.error(f\"mid_quote_diff: {mid_quote_diff}\")\n",
    "        logger.error(f\"df_calls_copy: {df_calls_copy} df_puts_copy: {df_puts_copy}\")\n",
    "        min_diff_strike = None\n",
    "\n",
    "    custom_print(\"min_diff_strike: \", min_diff_strike)\n",
    "    return min_diff_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_diff_strike_new(df_calls, df_puts, activation, near_term):\n",
    "    # Set the strike price as the index in both dataframes\n",
    "    df_calls_local = df_calls.copy()\n",
    "    df_puts_local = df_puts.copy()\n",
    "\n",
    "    df_calls_local['strike-copy'] = df_calls_local['strike']\n",
    "    df_puts_local['strike-copy'] = df_puts_local['strike']\n",
    "\n",
    "    df_calls_local.set_index('strike', inplace=True)\n",
    "    df_puts_local.set_index('strike', inplace=True)\n",
    "\n",
    "    # Find common strikes\n",
    "    common_strikes = df_calls_local.index.intersection(df_puts_local.index)\n",
    "\n",
    "    # Filter dataframes to only include common strikes\n",
    "    df_calls_local = df_calls_local.loc[common_strikes]\n",
    "    df_puts_local = df_puts_local.loc[common_strikes]\n",
    "\n",
    "    # Filter out rows where mid-quote is zero in both dataframes\n",
    "    non_zero_mask = ~((df_calls_local['mid-quote'] == 0)\n",
    "                      & (df_puts_local['mid-quote'] == 0))\n",
    "    df_calls_local = df_calls_local[non_zero_mask]\n",
    "    df_puts_local = df_puts_local[non_zero_mask]\n",
    "\n",
    "    # Calculate the difference between the mid-quote values\n",
    "    mid_quote_diff = (\n",
    "        df_calls_local['mid-quote'] - df_puts_local['mid-quote']).abs()\n",
    "\n",
    "    # Find the strike price with the minimum difference\n",
    "    try:\n",
    "        min_diff_strike = mid_quote_diff.idxmin()\n",
    "    except ValueError:\n",
    "        logger.error(\"Attempted to get argmin of an empty sequence.\")\n",
    "        logger.error(f\"mid_quote_diff: {mid_quote_diff}\")\n",
    "        logger.error(f\"df_calls_copy: {df_calls_copy} df_puts_copy: {df_puts_copy}\")\n",
    "        min_diff_strike = None    \n",
    "    custom_print(\"min_diff_strike: \", min_diff_strike)\n",
    "\n",
    "    #######################################################################################\n",
    "    forward = min_diff_strike + \\\n",
    "        activation * (df_calls.loc[df_calls['strike'] == min_diff_strike, 'mid-quote'].values[0] -\n",
    "                      df_puts.loc[df_puts['strike'] == min_diff_strike, 'mid-quote'].values[0])\n",
    "\n",
    "    custom_print(\"Forward: \", forward)\n",
    "\n",
    "    atm_strike_another = df_calls_local.loc[df_calls_local['strike-copy']\n",
    "                                            < forward, 'strike-copy'].max()\n",
    "    custom_print(\"atm_strike-another: \", atm_strike_another)\n",
    "\n",
    "    atm_strike = df_calls_local[df_calls_local['strike-copy']\n",
    "                                < forward]['strike-copy'].max()\n",
    "\n",
    "    custom_print(\"atm_strike: \", atm_strike)\n",
    "    ###display(HTML(df_calls_local.to_html(index=False, border=0)))\n",
    "    ###display(HTML(df_puts_local.to_html(index=False, border=0)))\n",
    "\n",
    "    row_calls = df_calls.loc[df_calls['strike']\n",
    "                             == atm_strike].reset_index(drop=True)\n",
    "    row_puts = df_puts.loc[df_puts['strike']\n",
    "                           == atm_strike].reset_index(drop=True)\n",
    "    average_values = (row_calls[['mid-quote', 'bid', 'ask', 'px_last']] +\n",
    "                      row_puts[['mid-quote', 'bid', 'ask', 'px_last']]) / 2\n",
    "    average_values['strike'] = atm_strike\n",
    "    average_values['option_type'] = 'ATM Avg Put/Call'\n",
    "    atm_df = average_values[['strike', 'bid', 'ask',\n",
    "                             'option_type', 'px_last', 'mid-quote']]\n",
    "\n",
    "    #######display(HTML(atm_df.to_html(index=False, border=0)))\n",
    "    return forward, atm_df, atm_strike\n",
    "    ##############################################################################################\n",
    "\n",
    "    # return min_diff_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preapare_data(df):\n",
    "    df = df.fillna(0)\n",
    "    # Split the dataframe into calls and puts\n",
    "    df_calls = df[df['option_type'] == 'C'].copy()\n",
    "    df_puts = df[df['option_type'] == 'P'].copy()\n",
    "\n",
    "    df_puts.loc[:, 'mid-quote'] = (df_puts['bid'] + df_puts['ask']) / 2\n",
    "    df_calls.loc[:, 'mid-quote'] = (df_calls['bid'] + df_calls['ask']) / 2\n",
    "\n",
    "    return df_calls, df_puts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def chain_of_responsibility(df, r, t, near_term=True):\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df_calls, df_puts = preapare_data(df)\n",
    "\n",
    "    # Remove the strikes with no bid price\n",
    "    df_puts, df_calls = [remove_strikes(\n",
    "        df_puts, 'Put'), remove_strikes(df_calls, 'Call')]\n",
    "\n",
    "    # if near_term is False:\n",
    "    #     display(HTML(df_puts.to_html(index=False, border=0)))\n",
    "    #     display(HTML(df_calls.to_html(index=False, border=0)))\n",
    "\n",
    "    # Find the min strike difference\n",
    "    ######min_diff_strike = find_min_diff_strike_new(df_calls, df_puts, near_term)\n",
    "\n",
    "    ###########################\n",
    "    activation = np.exp(r*t)\n",
    "    forward, df_atm, atm_strike = find_min_diff_strike_new(\n",
    "        df_calls, df_puts, activation, near_term)\n",
    "    ##########################\n",
    "\n",
    "    # Calculate Forwrard\n",
    "    # activation = np.exp(r*t)\n",
    "    # forward, df_atm, atm_strike = forward_and_atm(\n",
    "    #     min_diff_strike, df_calls.copy(), df_puts.copy(), activation, near_term)\n",
    "\n",
    "    # activation = np.exp(r*t)\n",
    "    # forward, df_atm, atm_strike = calculate_forward(\n",
    "    #     min_diff_strike, df_calls, df_puts, activation, near_term)\n",
    "\n",
    "    # Filter the dataframe to include only OTM strike\n",
    "    df_puts = df_puts[df_puts['strike'] < atm_strike]\n",
    "    df_calls = df_calls[df_calls['strike'] > atm_strike]\n",
    "\n",
    "    # Remove the strikes with no bid price\n",
    "    df_puts, df_calls = [remove_strikes(\n",
    "        df_puts, 'Put'), remove_strikes(df_calls, 'Call')]\n",
    "\n",
    "    # Combine data frames\n",
    "    df_otm = pd.concat([df_puts, df_atm, df_calls], ignore_index=True)\n",
    "    df_otm = df_otm.sort_values('strike')\n",
    "\n",
    "    # Add adjescent strike difference\n",
    "    df_otm = add_strike_diff(df_otm)\n",
    "\n",
    "    # Contribution per Strike\n",
    "    df_otm['strike_squared'] = df_otm['strike'] ** 2\n",
    "    df_otm['strike_contribution'] = (\n",
    "        df_otm['strike_diff'] * df_otm['mid-quote'] * activation)/df_otm['strike_squared']\n",
    "\n",
    "    #display(HTML(df_otm.to_html(index=False, border=0)))\n",
    "    total_contribution = 2 * df_otm['strike_contribution'].sum()/t\n",
    "    #print(\"Total contribution\", total_contribution)\n",
    "    decay = ((forward/atm_strike - 1) ** 2)/t\n",
    "\n",
    "    sigma_squared = (total_contribution - decay)\n",
    "    ################################Per strike Quantity Contribution####################################\n",
    "    df_otm['per_strike_qunatity_contribution'] = (df_otm['strike_diff'] * activation)/df_otm['strike_squared']\n",
    "    df_otm['per_strike_quantity_term_adjustment'] = (2 * df_otm['per_strike_qunatity_contribution'])/t\n",
    "    ###################################################################################################\n",
    "    \n",
    "    ######print(\"Sigma squared\", sigma_squared)\n",
    "    #display(HTML(df_otm.to_html(index=False, border=0)))\n",
    "    return sigma_squared, df_otm, atm_strike, forward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start_date' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tick'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 23\u001b[0m, in \u001b[0;36mcreate_dataset_from_data_stream_fut\u001b[1;34m(expiry_date, instrument_type, req_type, sec)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# Create a new DataFrame from the 'tick' column\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     tick_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtick\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mtolist(), columns\u001b[38;5;241m=\u001b[39mtick_columns)\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Drop the 'tick' column from the original DataFrame\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:3893\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3892\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3893\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'tick'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 52\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;66;03m#working_set.to_csv('./historical/output.csv', index=False)\u001b[39;00m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;66;03m#working_set.to_json('./historical/output.json', index=False)\u001b[39;00m\n\u001b[0;32m     47\u001b[0m     \u001b[38;5;66;03m######display(HTML(working_set.to_html(index=False, border=0)))\u001b[39;00m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m     \u001b[38;5;66;03m# Return the response\u001b[39;00m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m working_set\n\u001b[1;32m---> 52\u001b[0m working_set \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_dataset_from_data_stream_fut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexpiry_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstrument_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moption\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_type\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquote\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msec\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSPXW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[28], line 41\u001b[0m, in \u001b[0;36mcreate_dataset_from_data_stream_fut\u001b[1;34m(expiry_date, instrument_type, req_type, sec)\u001b[0m\n\u001b[0;32m     39\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     40\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpiry date: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpiry_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStart date: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mstart_date\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     42\u001b[0m logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgram state: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_date' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def create_dataset_from_data_stream_fut(expiry_date, instrument_type = 'option', req_type = 'quote', sec = 'SPXW'):\n",
    "    # Define the base URL\n",
    "    base_url = \"http://127.0.0.1:25510/bulk_snapshot\"\n",
    "    request_url = f\"{base_url}/{instrument_type}/{req_type}\"\n",
    "    params = {\n",
    "        \n",
    "        \"exp\": expiry_date,    \n",
    "        \"root\": sec\n",
    "    }\n",
    "    # Send the request\n",
    "    response = requests.get(request_url, params=params, headers={'Accept': 'application/json'})\n",
    "\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.json_normalize(data['response'])\n",
    "    tick_columns = [\"ms_of_day\", \"bid_size\", \"bid_exchange\", \"bid\", \"bid_condition\", \"ask_size\", \"ask_exchange\", \"ask\", \"ask_condition\", \"date\"]\n",
    "    try:\n",
    "        # Create a new DataFrame from the 'tick' column\n",
    "        tick_df = pd.DataFrame(df['tick'].tolist(), columns=tick_columns)\n",
    "\n",
    "        # Drop the 'tick' column from the original DataFrame\n",
    "        df = df.drop('tick', axis=1)\n",
    "\n",
    "        # Concatenate the original DataFrame with the new DataFrame\n",
    "        df = pd.concat([df, tick_df], axis=1)\n",
    "\n",
    "        df['strike'] = df['contract.strike']/1000\n",
    "        df.sort_values(by=['strike'], inplace=True)\n",
    "        df = df.rename(columns={'contract.right': 'option_type'})\n",
    "        working_set = df[['strike', 'bid', 'ask', 'option_type']].copy()\n",
    "        working_set.loc[:, 'px_last'] = 999\n",
    "        ###working_set['px_last'] = 999\n",
    "    except Exception as e:\n",
    "        # Log the error message and the program state\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        logger.error(f\"Expiry date: {expiry_date}\")\n",
    "        logger.error(f\"Start date: {start_date}\")\n",
    "        logger.error(f\"Program state: {df}\")\n",
    "        return None\n",
    "\n",
    "    #working_set.to_csv('./historical/output.csv', index=False)\n",
    "    #working_set.to_json('./historical/output.json', index=False)\n",
    "    ######display(HTML(working_set.to_html(index=False, border=0)))\n",
    "\n",
    "    # Return the response\n",
    "    return working_set\n",
    "\n",
    "working_set = create_dataset_from_data_stream_fut(expiry_date, instrument_type = 'option', req_type = 'quote', sec = 'SPXW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def create_dataset_from_data_stream(instrument_type, req_type, sec, start_date, end_date, expiry_date, ivl):\n",
    "    # Define the base URL\n",
    "    base_url = \"http://127.0.0.1:25510/bulk_at_time\"\n",
    "\n",
    "    # Construct the request URL\n",
    "    request_url = f\"{base_url}/{instrument_type}/{req_type}\"\n",
    "\n",
    "    # Define the query parameters\n",
    "    params = {\n",
    "        \"end_date\": end_date,\n",
    "        \"exp\": expiry_date,\n",
    "        \"ivl\": ivl,\n",
    "        \"root\": sec,\n",
    "        \"start_date\": start_date\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.get(request_url, params=params)\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.json_normalize(data['response'])\n",
    "    tick_columns = [\"ms_of_day\", \"bid_size\", \"bid_exchange\", \"bid\", \"bid_condition\", \"ask_size\", \"ask_exchange\", \"ask\", \"ask_condition\", \"date\"]\n",
    "    try:\n",
    "        df[tick_columns] = df['ticks'].apply(lambda x: pd.Series(x[0]))\n",
    "        df['strike'] = df['contract.strike']/1000\n",
    "        df.sort_values(by=['strike'], inplace=True)\n",
    "        df = df.rename(columns={'contract.right': 'option_type'})\n",
    "        working_set = df[['strike', 'bid', 'ask', 'option_type']].copy()\n",
    "        working_set.loc[:, 'px_last'] = 999\n",
    "        ###working_set['px_last'] = 999\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error message and the program state\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        logger.error(f\"Expiry date: {expiry_date}\")\n",
    "        logger.error(f\"Start date: {start_date}\")\n",
    "        logger.error(f\"Program state: {df}\")\n",
    "        return None\n",
    "        \n",
    "\n",
    "    #working_set.to_csv('./historical/output.csv', index=False)\n",
    "    #working_set.to_json('./historical/output.json', index=False)\n",
    "    #display(HTML(working_set.to_html(index=False, border=0)))\n",
    "\n",
    "    # Return the response\n",
    "    return working_set\n",
    "\n",
    "trade_date, end_date, expiry_date = '20230214', '20230214', '20230215' \n",
    "working_set = create_dataset_from_data_stream('option', 'quote', 'SPXW', trade_date, end_date, expiry_date, 57675000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\vix_utils\\download_vix_futures.py:72: FutureWarning: The behavior of DatetimeProperties.to_pydatetime is deprecated, in a future version this will return a Series containing python datetime objects instead of an ndarray. To retain the old behavior, call `np.array` on the result\n",
      "  self.valid_days_set=frozenset(d.date() for d in self.valid_days.dt.to_pydatetime())\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "# Time to expiration\n",
    "import vix_utils\n",
    "\n",
    "def spawn_backtest(vix_future_settlement_date, calc_date):\n",
    "    eod = {\n",
    "        \"year\": vix_future_settlement_date.year,\n",
    "        \"month\": vix_future_settlement_date.month,\n",
    "        \"day\": vix_future_settlement_date.day,\n",
    "        \"hour\": 16,\n",
    "        \"minute\": 15,\n",
    "        \"second\": 0\n",
    "    }\n",
    "\n",
    "    delta = abs(datetime.datetime.now() - calc_date)\n",
    "    ####print(f\"Time delta : {delta} \")\n",
    "    custom_print(\"delta: \", delta)\n",
    "\n",
    "\n",
    "    l_t1, l_t2 = chicago_eod_four_PM(\n",
    "        eod, near_term=True), chicago_eod_four_PM(eod, near_term=False)\n",
    "\n",
    "    start_date = calc_date.strftime('%Y%m%d')\n",
    "    end_date =   calc_date.strftime('%Y%m%d')\n",
    "\n",
    "    option_expiry_near = l_t1[1].strftime('%Y%m%d')\n",
    "    option_expiry_next = l_t2[1].strftime('%Y%m%d')\n",
    "    \n",
    "    forward_days = (vix_future_settlement_date - calc_date).days * 1440\n",
    "\n",
    "    n_t1 = l_t1[0] + forward_days\n",
    "    n_t2 = l_t2[0] + forward_days\n",
    "\n",
    "    print(f\"n_t1 and n_t2 {n_t1} {n_t2} \")\n",
    "\n",
    "    # extrapolated rates to expiration\n",
    "    r_near, r_next = np.array(cubic_spline_risk_free_rate(\n",
    "        [n_t1, n_t2], days = delta))/100\n",
    "    custom_print(\"r_near and r_next\", r_near, r_next, )\n",
    "    custom_print(f\"start_date : {start_date}, end_date : {end_date}, option_expiry_near : {option_expiry_near}, option_expiry_next : {option_expiry_next}\")\n",
    "    print(f\"start_date : {start_date}, end_date : {end_date}, option_expiry_near : {option_expiry_near}, option_expiry_next : {option_expiry_next}\")\n",
    "    t_near = n_t1/525600\n",
    "    t_next = n_t2/525600\n",
    "\n",
    "    df_near = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = start_date, \n",
    "                                             end_date = start_date, expiry_date = option_expiry_near, ivl = 57675000)\n",
    "\n",
    "\n",
    "    df_next = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = start_date, \n",
    "                                             end_date = start_date, expiry_date = option_expiry_next, ivl = 57675000)\n",
    "    \n",
    "    \n",
    "    if df_near is None or df_next is None:\n",
    "        return None\n",
    "                                        \n",
    "    sigma_squared_near, df_vix_near, atm_near, forward_near = chain_of_responsibility(df_near, r_near, t_near) \n",
    "    sigma_squared_next, df_vix_next, atm_next,forward_next = chain_of_responsibility(df_next, r_next, t_next, False)\n",
    "    \n",
    "    atm_near_details = df_vix_near.loc[df_vix_near['strike'] == atm_near]\n",
    "    atm_next_details = df_vix_next.loc[df_vix_next['strike'] == atm_next]                                        \n",
    "\n",
    "    custom_print(\"Sigma squared near\", sigma_squared_near)\n",
    "    custom_print(\"Sigma squared next\", sigma_squared_next)\n",
    "\n",
    "    n_30 = 43200 + forward_days\n",
    "    n_365 = 525600\n",
    "    n_y_m = n_365/n_30\n",
    "\n",
    "    tnear_sig_squared = sigma_squared_near * t_near\n",
    "    tnext_sig_squared = sigma_squared_next * t_next\n",
    "\n",
    "\n",
    "    near_dev = tnear_sig_squared * ((n_t2 - n_30)/(n_t2 - n_t1))\n",
    "    next_dev = tnext_sig_squared * ((n_30 - n_t1)/(n_t2 - n_t1))\n",
    "    tot_dev = near_dev + next_dev\n",
    "    vix = np.sqrt(tot_dev * n_y_m) * 100\n",
    "\n",
    "    print(f'Vix Forward on {start_date} - {vix}')\n",
    "    #######print(f'atm_near - {atm_near}')\n",
    "    ########print(f'atm_next - {atm_next}')\n",
    "\n",
    "    ################################################\n",
    "    df_vix_near['T1'] = t_near\n",
    "    df_vix_near['(M_t2 - M_30)/(M_t2 - M_t1)'] = (n_t2 - n_30)/(n_t2 - n_t1)\n",
    "    df_vix_near['M_365/M_30'] = n_y_m\n",
    "\n",
    "    df_vix_near['per_strike_constants'] = df_vix_near['per_strike_quantity_term_adjustment'] * n_y_m * t_near * (n_t2 - n_30)/(n_t2 - n_t1)\n",
    " \n",
    "    df_vix_next['T2'] = t_next\n",
    "    df_vix_next['(M_30 - M_t1)/(M_t2 - M_t1)'] = (n_30 - n_t1)/(n_t2 - n_t1)\n",
    "    df_vix_next['M_365/M_30'] = n_y_m\n",
    "\n",
    "    df_vix_next['per_strike_constants'] = df_vix_next['per_strike_quantity_term_adjustment'] * n_y_m * t_next * (n_30 - n_t1)/(n_t2 - n_t1)\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    return vix, df_near, df_next, df_vix_near, df_vix_next, forward_near, forward_next, start_date, option_expiry_near, option_expiry_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_df_to_csv(df, path):\n",
    "    # Extract directory from the path\n",
    "    dir_path = os.path.dirname(path)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(dir_path):\n",
    "        # If the directory doesn't exist, create it\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(path, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory_structure(trade_date):\n",
    "    # Define the directories to be created\n",
    "    directories = [\n",
    "        f'./result-set/{trade_date}',\n",
    "        f'./result-set/{trade_date}/future',\n",
    "        f'./result-set/{trade_date}/P&L',\n",
    "        f'./result-set/{trade_date}/P&L/Delta-25&Above',\n",
    "        f'./result-set/{trade_date}/spot'\n",
    "    ]\n",
    "\n",
    "    # Iterate over the directories\n",
    "    for directory in directories:\n",
    "        # Check if the directory does not already exist\n",
    "        if not os.path.exists(directory):\n",
    "            # Create the directory\n",
    "            os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicating Vix future for 2023-02-15 on 2023-02-01 16:15:00\n",
      "n_t1 and n_t2 61515 71985 \n",
      "start_date : 20230201, end_date : 20230201, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230201 - 19.565824841154186\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-02 16:15:00\n",
      "n_t1 and n_t2 60075 70545 \n",
      "start_date : 20230202, end_date : 20230202, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230202 - 19.88614199609086\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-03 16:15:00\n",
      "n_t1 and n_t2 58635 69105 \n",
      "start_date : 20230203, end_date : 20230203, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230203 - 19.813355318359154\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-06 16:15:00\n",
      "n_t1 and n_t2 54315 64785 \n",
      "start_date : 20230206, end_date : 20230206, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230206 - 20.598331845159784\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-07 16:15:00\n",
      "n_t1 and n_t2 52875 63345 \n",
      "start_date : 20230207, end_date : 20230207, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230207 - 19.793164332117087\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-08 16:15:00\n",
      "n_t1 and n_t2 51435 61905 \n",
      "start_date : 20230208, end_date : 20230208, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230208 - 20.742911780078334\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-09 16:15:00\n",
      "n_t1 and n_t2 49995 60465 \n",
      "start_date : 20230209, end_date : 20230209, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230209 - 21.729908691066786\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-10 16:15:00\n",
      "n_t1 and n_t2 48555 59025 \n",
      "start_date : 20230210, end_date : 20230210, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230210 - 21.525146167333972\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-13 16:15:00\n",
      "n_t1 and n_t2 44235 54705 \n",
      "start_date : 20230213, end_date : 20230213, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230213 - 21.09629212167769\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-14 16:15:00\n",
      "n_t1 and n_t2 42795 53265 \n",
      "start_date : 20230214, end_date : 20230214, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230214 - 19.36844965842121\n",
      "Replicating Vix future for 2023-02-15 on 2023-02-15 16:15:00\n",
      "n_t1 and n_t2 41355 51825 \n",
      "start_date : 20230215, end_date : 20230215, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230215 - 18.765129627479837\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-16 16:15:00\n",
      "n_t1 and n_t2 90315 100785 \n",
      "start_date : 20230216, end_date : 20230216, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230216 - 21.217318603306946\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-17 16:15:00\n",
      "n_t1 and n_t2 88875 99345 \n",
      "start_date : 20230217, end_date : 20230217, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230217 - 21.02096036498636\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-20 16:15:00\n",
      "n_t1 and n_t2 84555 95025 \n",
      "start_date : 20230220, end_date : 20230220, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230220 - 21.637620024716\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-21 16:15:00\n",
      "n_t1 and n_t2 83115 93585 \n",
      "start_date : 20230221, end_date : 20230221, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230221 - 23.080353184887045\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-22 16:15:00\n",
      "n_t1 and n_t2 81675 92145 \n",
      "start_date : 20230222, end_date : 20230222, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230222 - 22.38320592655186\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-23 16:15:00\n",
      "n_t1 and n_t2 80235 90705 \n",
      "start_date : 20230223, end_date : 20230223, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230223 - 21.353350236559578\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-24 16:15:00\n",
      "n_t1 and n_t2 78795 89265 \n",
      "start_date : 20230224, end_date : 20230224, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230224 - 22.003391041249625\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-27 16:15:00\n",
      "n_t1 and n_t2 74475 84945 \n",
      "start_date : 20230227, end_date : 20230227, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230227 - 21.20352187143105\n",
      "Replicating Vix future for 2023-03-22 on 2023-02-28 16:15:00\n",
      "n_t1 and n_t2 73035 83505 \n",
      "start_date : 20230228, end_date : 20230228, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230228 - 20.776331541788377\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-01 16:15:00\n",
      "n_t1 and n_t2 71595 82065 \n",
      "start_date : 20230301, end_date : 20230301, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230301 - 20.97244177478642\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-02 16:15:00\n",
      "n_t1 and n_t2 70155 80625 \n",
      "start_date : 20230302, end_date : 20230302, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230302 - 20.014185524903688\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-03 16:15:00\n",
      "n_t1 and n_t2 68715 79185 \n",
      "start_date : 20230303, end_date : 20230303, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230303 - 19.167775952241815\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-06 16:15:00\n",
      "n_t1 and n_t2 64395 74865 \n",
      "start_date : 20230306, end_date : 20230306, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230306 - 19.16107606526954\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-07 16:15:00\n",
      "n_t1 and n_t2 62955 73425 \n",
      "start_date : 20230307, end_date : 20230307, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230307 - 19.956268465094812\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-08 16:15:00\n",
      "n_t1 and n_t2 61515 71985 \n",
      "start_date : 20230308, end_date : 20230308, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230308 - 19.47751534233533\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-09 16:15:00\n",
      "n_t1 and n_t2 60075 70545 \n",
      "start_date : 20230309, end_date : 20230309, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230309 - 22.389826073185702\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-10 16:15:00\n",
      "n_t1 and n_t2 58635 69105 \n",
      "start_date : 20230310, end_date : 20230310, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230310 - 24.973391624212084\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-13 16:15:00\n",
      "n_t1 and n_t2 54315 64785 \n",
      "start_date : 20230313, end_date : 20230313, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230313 - 26.837979165531678\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-14 16:15:00\n",
      "n_t1 and n_t2 52875 63345 \n",
      "start_date : 20230314, end_date : 20230314, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230314 - 23.984090802792956\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-15 16:15:00\n",
      "n_t1 and n_t2 51435 61905 \n",
      "start_date : 20230315, end_date : 20230315, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230315 - 26.06965946127215\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-16 16:15:00\n",
      "n_t1 and n_t2 49995 60465 \n",
      "start_date : 20230316, end_date : 20230316, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230316 - 23.45612982337591\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-17 16:15:00\n",
      "n_t1 and n_t2 48555 59025 \n",
      "start_date : 20230317, end_date : 20230317, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230317 - 25.881107624573996\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-20 16:15:00\n",
      "n_t1 and n_t2 44235 54705 \n",
      "start_date : 20230320, end_date : 20230320, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230320 - 24.734884160066386\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-21 16:15:00\n",
      "n_t1 and n_t2 42795 53265 \n",
      "start_date : 20230321, end_date : 20230321, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230321 - 22.021714780498552\n",
      "Replicating Vix future for 2023-03-22 on 2023-03-22 16:15:00\n",
      "n_t1 and n_t2 41355 51825 \n",
      "start_date : 20230322, end_date : 20230322, option_expiry_near : 20230421, option_expiry_next : 20230428\n",
      "Vix Forward on 20230322 - 22.85545481464455\n"
     ]
    }
   ],
   "source": [
    "###Backtesting for a single date\n",
    "import datetime\n",
    "\n",
    "def run_backtest(year, month, day):\n",
    "    try:\n",
    "        ins_type = \"future\"\n",
    "        \n",
    "        v = vix_utils.vix_futures_expiry_date_from_trade_date(year, month, day, 1) if ins_type == \"future\" else datetime.datetime(year, month, day)\n",
    "        on_day = datetime.datetime.combine(datetime.datetime(year, month, day), datetime.time(16, 15, 0))\n",
    "        vix_future_settlement_day = datetime.datetime.combine(v, datetime.time())\n",
    "        print(f\"Replicating Vix {ins_type} for {v} on {on_day}\")\n",
    "        \n",
    "        create_directory_structure(on_day.strftime('%Y-%m-%d'))\n",
    "        vix, df_near, df_next, df_vix_near, df_vix_next, forward_near, forward_next, start_date, option_expiry_near, option_expiry_next = spawn_backtest(vix_future_settlement_day, on_day)\n",
    "        \n",
    "        df_near['mid_quote'] = (df_near['bid'] + df_near['ask']) / 2\n",
    "        df_next['mid_quote'] = (df_next['bid'] + df_next['ask']) / 2\n",
    "        #######################################################\n",
    "        df_per_strike_quantity_near = df_vix_near[['strike', 'option_type', 'mid-quote', 'per_strike_quantity_term_adjustment',\\\n",
    "                                                    'T1', '(M_t2 - M_30)/(M_t2 - M_t1)', 'M_365/M_30', 'per_strike_constants' ]].copy()\n",
    "        df_per_strike_quantity_next = df_vix_next[['strike', 'option_type', 'mid-quote', 'per_strike_quantity_term_adjustment',\\\n",
    "                                                    'T2', '(M_30 - M_t1)/(M_t2 - M_t1)', 'M_365/M_30', 'per_strike_constants']].copy()\n",
    "        \n",
    "        df_per_strike_quantity_near = df_per_strike_quantity_near.rename(columns={'mid-quote': 'mid_quote'})\n",
    "        df_per_strike_quantity_next = df_per_strike_quantity_next.rename(columns={'mid-quote': 'mid_quote'})\n",
    "        df_per_strike_quantity_near['vix_forward'] = vix\n",
    "        df_per_strike_quantity_next['vix_forward'] = vix\n",
    "        observation_date = on_day.strftime('%Y-%m-%d')\n",
    "        save_df_to_csv(df_per_strike_quantity_near, f'./result-set/{observation_date}/{ins_type}/dataset_{option_expiry_near}.csv')\n",
    "        save_df_to_csv(df_per_strike_quantity_next, f'./result-set/{observation_date}/{ins_type}/dataset_{option_expiry_next}.csv')\n",
    "\n",
    "        if vix_future_settlement_day.date() == on_day.date():\n",
    "            save_df_to_csv(df_near, f'./result-set/{observation_date}/{ins_type}/dataset_complete_{option_expiry_near}.csv')\n",
    "            save_df_to_csv(df_next, f'./result-set/{observation_date}/{ins_type}/dataset_complete_{option_expiry_next}.csv')\n",
    "        ########################################################\n",
    "\n",
    "        \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred on {year}-{month}-{day}: {e}\")\n",
    "        return None\n",
    "\n",
    "results = {}\n",
    "business_days = pd.bdate_range(start='2023-02-01', end='2023-03-22')\n",
    "for day in business_days:\n",
    "    result = run_backtest(day.year, day.month, day.day)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_delta_r(df):\n",
    "    def find_option(option_type, target_delta, attribute_name):\n",
    "        options = df[df['option_type'] == option_type]\n",
    "        closest_option_index = (options['Delta'] - target_delta).abs().idxmin()\n",
    "        df.loc[closest_option_index, 'Strike_attribute'] = attribute_name\n",
    "        corresponding_option = df[(df['strike'] == df.loc[closest_option_index, 'strike']) & (df['option_type'] == ('C' if option_type == 'P' else 'P'))]\n",
    "        if not corresponding_option.empty:\n",
    "            df.loc[closest_option_index, 'other_strike_mid_quote'] = corresponding_option['mid_quote'].iloc[0]\n",
    "        return df.loc[closest_option_index]\n",
    "\n",
    "    closest_call = find_option('C', 0.25, '25 Delta Call')\n",
    "    closest_put = find_option('P', -0.25, '25 Delta Put')\n",
    "\n",
    "    return closest_call, closest_put"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_delta(df):\n",
    "    # For call options, find the row with Delta closest to 0.25\n",
    "    call_options = df[df['option_type'] == 'C']\n",
    "    closest_call_index = (call_options['Delta'] - 0.25).abs().idxmin()\n",
    "    df.loc[closest_call_index, 'Strike_attribute'] = '25 Delta Call'\n",
    "    \n",
    "    # For put options, find the row with Delta closest to -0.25\n",
    "    put_options = df[df['option_type'] == 'P']\n",
    "    closest_put_index = (put_options['Delta'] - (-0.25)).abs().idxmin()\n",
    "    df.loc[closest_put_index, 'Strike_attribute'] = '25 Delta Put'\n",
    "    \n",
    "    # Find the corresponding mid quote for the closest call and put options\n",
    "    corresponding_put = df[(df['strike'] == df.loc[closest_call_index, 'strike']) & (df['option_type'] == 'P')]\n",
    "    if not corresponding_put.empty:\n",
    "        df.loc[closest_call_index, 'other_strike_mid_quote'] = corresponding_put['mid-quote'].iloc[0]\n",
    "        \n",
    "    corresponding_call = df[(df['strike'] == df.loc[closest_put_index, 'strike']) & (df['option_type'] == 'C')]\n",
    "    if not corresponding_call.empty:\n",
    "        df.loc[closest_put_index, 'other_strike_mid_quote'] = corresponding_call['mid-quote'].iloc[0]\n",
    "    \n",
    "    return df.loc[closest_call_index], df.loc[closest_put_index]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
