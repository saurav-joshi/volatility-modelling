{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import re\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "from IPython.display import display, HTML\n",
    "from scipy import interpolate\n",
    "from yahoo_fin import options as op, stock_info as si\n",
    "\n",
    "import logging\n",
    "\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a file handler\n",
    "handler = logging.FileHandler('error_log.txt')\n",
    "handler.setLevel(logging.ERROR)\n",
    "\n",
    "# Create a formatter and add it to the handler\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "handler.setFormatter(formatter)\n",
    "\n",
    "# Add the handler to the logger\n",
    "logger.addHandler(handler)\n",
    "\n",
    "# Global flag for controlling print statements\n",
    "enable_print = False\n",
    "\n",
    "def custom_print(*args, **kwargs):\n",
    "    global enable_print\n",
    "    if enable_print:\n",
    "        print(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4780.93994140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\yahoo_fin\\stock_info.py:580: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.close[-1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from yahoo_fin import options as op, stock_info as si\n",
    "s = si.get_live_price(\"^GSPC\")\n",
    "print(s)\n",
    "l = [1.0, 2.0, 3.0, 4.0, 5.0, 6.0]\n",
    "l[:-2]\n",
    "l[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volatility I.V\n",
      "3580.9556062697693 0.015007329453080726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\yahoo_fin\\stock_info.py:580: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  return df.close[-1]\n"
     ]
    }
   ],
   "source": [
    "import mibian\n",
    "\n",
    "# Define the parameters\n",
    "underlyingPrice = si.get_live_price(\"^GSPC\")\n",
    "strikePrice = 1200\n",
    "interestRate = 0.01\n",
    "daysToExpiration = 2\n",
    "optionPrice = 0.025 #3360.5 \t\n",
    "option_type = 'None'\n",
    "volatility = 492.1875 #0.00010 \n",
    "\n",
    "# Create an instance of the BS class with the parameters\n",
    "if option_type == 'C':\n",
    "    print('Call I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], callPrice=optionPrice)\n",
    "elif option_type == 'P':\n",
    "    print('Put I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], putPrice=optionPrice)\n",
    "elif volatility != None:\n",
    "    print('Volatility I.V')\n",
    "    bs = mibian.BS([underlyingPrice, strikePrice, interestRate, daysToExpiration], volatility=volatility)    \n",
    "    print(bs.callPrice, bs.putPrice)\n",
    "else:\n",
    "    print('Invalid option type')    \n",
    "\n",
    "# Print the implied volatility\n",
    "if volatility == None:\n",
    "    print(bs.impliedVolatility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to expiration:  2023-02-10 00:00:00-05:00 2023-02-17 00:00:00-05:00\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pytz\n",
    "\n",
    "\n",
    "def chicago_eod_four_PM(eod, near_term=True):\n",
    "    # Create a datetime object for 4 PM on November 10\n",
    "    # replace 2023 with the correct year\n",
    "    # 14.17 as of 11th Nov 2020\n",
    "    four_pm = datetime.datetime(\n",
    "        eod['year'], eod['month'], eod['day'], eod['hour'], eod['minute'], 0)  # 10th Nov 2023\n",
    "\n",
    "    # Convert the datetime object to Eastern Time\n",
    "    eastern = pytz.timezone('US/Eastern')\n",
    "    four_pm_et = eastern.localize(four_pm)\n",
    "    custom_print(\"four_pm_et: \", four_pm_et)\n",
    "\n",
    "    tomorrow = datetime.datetime(\n",
    "        four_pm_et.year, four_pm_et.month, four_pm_et.day, tzinfo=four_pm_et.tzinfo) + datetime.timedelta(1)\n",
    "    days = [four_pm_et + datetime.timedelta(index) for index in range(24, 38)]\n",
    "\n",
    "    friday = next(day for day in days if day.weekday() == 4)\n",
    "    next_term = -1 if near_term == True else 6\n",
    "    days_to_expiration = (friday - four_pm_et).days + next_term\n",
    "    expiration_day = datetime.datetime(\n",
    "        four_pm_et.year, four_pm_et.month, four_pm_et.day,\n",
    "        tzinfo=four_pm_et.tzinfo) + datetime.timedelta(days_to_expiration + 1)\n",
    "    custom_print(\"days to expiration: \", days_to_expiration)\n",
    "    custom_print(\"friday: \", friday)\n",
    "    custom_print(\"expiration day: \", expiration_day)\n",
    "    custom_print(\"expiration day - calculation day: \", expiration_day - four_pm_et)\n",
    "\n",
    "    # minutes_to_settlement = 570 if friday.day in range(     #friday.day to expiration_day.day will cover near and next term\n",
    "    #     15, 22) and friday.weekday() == 4 else 960\n",
    "\n",
    "    minutes_to_settlement = 570 if expiration_day.day in range(\n",
    "        15, 22) and friday.weekday() == 4 else 960\n",
    "\n",
    "    minutes_to_midnight_today = (tomorrow - four_pm_et).seconds // 60\n",
    "    minutes_to_expiration = days_to_expiration * 24 * 60\n",
    "\n",
    "    custom_print(minutes_to_midnight_today, minutes_to_settlement, minutes_to_expiration)\n",
    "    time_to_expiration = (minutes_to_midnight_today +\n",
    "                          minutes_to_settlement + minutes_to_expiration)\n",
    "\n",
    "    # time_to_expiration = (minutes_to_midnight_today +\n",
    "    #                       minutes_to_settlement + minutes_to_expiration) / 525600\n",
    "\n",
    "    return (time_to_expiration, expiration_day, four_pm_et, days_to_expiration)\n",
    "\n",
    "\n",
    "yesterday = datetime.datetime(2023, 1, 16) - datetime.timedelta(days=0)\n",
    "eod = {\n",
    "    \"year\": yesterday.year,\n",
    "    \"month\": yesterday.month,\n",
    "    \"day\": yesterday.day,\n",
    "    \"hour\": 16,\n",
    "    \"minute\": 15,\n",
    "    \"second\": 0\n",
    "}\n",
    "print(\"Time to expiration: \", chicago_eod_four_PM(\n",
    "    eod, True)[1], chicago_eod_four_PM(eod, False)[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[43804,\n",
       "  87608,\n",
       "  131412,\n",
       "  175216,\n",
       "  262824,\n",
       "  525600,\n",
       "  1051200,\n",
       "  1576800,\n",
       "  2628000,\n",
       "  3679200,\n",
       "  5256000,\n",
       "  10512000,\n",
       "  15768000],\n",
       " ['4.58',\n",
       "  '4.64',\n",
       "  '4.70',\n",
       "  '4.74',\n",
       "  '4.80',\n",
       "  '4.68',\n",
       "  '4.21',\n",
       "  '3.90',\n",
       "  '3.63',\n",
       "  '3.59',\n",
       "  '3.52',\n",
       "  '3.78',\n",
       "  '3.65']]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "\n",
    "def scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale(days = 0):\n",
    "    \"\"\"\n",
    "    Retrieves and formats the US Treasury yield curve.\n",
    "    No arguments.\n",
    "    \"\"\"\n",
    "    calctime = datetime.datetime.now() - datetime.timedelta(days)\n",
    "    year = calctime.year\n",
    "    month = calctime.month\n",
    "    custom_print(year, month)\n",
    "    # year = datetime.datetime.now().year\n",
    "    # month = datetime.datetime.now().month\n",
    "    url = f\"https://home.treasury.gov/resource-center/data-chart-center/interest-rates/pages/xmlview?data=daily_treasury_yield_curve&field_tdr_date_value_month={year}{month:02d}\"\n",
    "    response = requests.get(url)\n",
    "\n",
    "    #print(json.dumps(response.content.decode(), indent=4))\n",
    "    root = ET.fromstring(response.content)\n",
    "\n",
    "    temp_us_treasury_dict = {}\n",
    "    us_treasury_dict = {}\n",
    "\n",
    "    for elt in root.iter():\n",
    "        temp_us_treasury_dict[elt.tag[-8:]] = elt.text\n",
    "\n",
    "    for key in temp_us_treasury_dict.keys():\n",
    "        if (key.find(\"MONTH\") + key.find(\"YEAR\") + key.find(\"DATE\") != -3):\n",
    "            us_treasury_dict[re.sub(r'.*_', '', key)\n",
    "                             ] = temp_us_treasury_dict[key]\n",
    "\n",
    "    # Based on the average number of day in a month: 30.42\n",
    "    minutes_in_a_month = 43804\n",
    "    minutes_in_a_year = 525600\n",
    "\n",
    "    # minute axis\n",
    "    #x = [int(key[:-5])*minutes_in_a_month if \"MONTH\" in key else int(key[:-4])*minutes_in_a_year if \"YEAR\" in key else None for key in us_treasury_dict.keys()]\n",
    "    x = [int(key[:-5])*minutes_in_a_month if \"MONTH\" in key else int(key[:-4]) *\n",
    "         minutes_in_a_year if \"YEAR\" in key else None for key in us_treasury_dict.keys() if \"MONTH\" in key or \"YEAR\" in key]\n",
    "\n",
    "    # yield axis\n",
    "    y = [us_treasury_dict[key]\n",
    "         for key in us_treasury_dict.keys() if \"MONTH\" in key or \"YEAR\" in key]\n",
    "    custom_print(\"Yield curve:\", us_treasury_dict)\n",
    "    custom_print(\"Yield curve in minutes scale:\", dict(zip(x, y)))\n",
    "\n",
    "    return [x, y]\n",
    "\n",
    "r = scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale(days = 365)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import CubicSpline\n",
    "from datetime import date\n",
    "import math\n",
    "\n",
    "\n",
    "def cubic_spline_risk_free_rate(minutes_to_expiration, days = 0):\n",
    "    \"\"\"\n",
    "    Estimates the risk free rate (based on the US treasury yield) at a specific time to expiration\n",
    "    :param <time_to_expiration>: integer ; time to expiration in day or minutes \n",
    "    :param <minute_data>: boolean ; indicates if the argument <time_to_expiration> is in minutes or days\n",
    "    \"\"\"\n",
    "\n",
    "    # Extract the tenors and corresponding yields from the US Treasury yield curve\n",
    "    yc = scrape_us_treasury_yield_curve_and_transpose_it_to_minutes_scale()\n",
    "    tenors = yc[0]\n",
    "    rates = yc[1]\n",
    "\n",
    "    # Sort the data by tenor\n",
    "    sorted_indices = np.argsort(tenors)\n",
    "    # print(sorted_indices)\n",
    "    #tenors_sorted = tenors[sorted_indices.tolist()]\n",
    "    #rates_sorted = rates[sorted_indices.tolist()]\n",
    "\n",
    "    tenors_sorted = [tenors[i] for i in sorted_indices]\n",
    "    rates_sorted = [rates[i] for i in sorted_indices]\n",
    "\n",
    "    # print(tenors_sorted)\n",
    "    # print(rates_sorted)\n",
    "\n",
    "    # Create a cubic spline interpolator\n",
    "    cs = CubicSpline(tenors_sorted, rates_sorted,\n",
    "                     extrapolate=True)  # Allow extrapolation\n",
    "\n",
    "    # Specify expiration dates of near-term and next-term options (replace with actual dates)\n",
    "    #near_term_expiration = date(2023, 12, 31)\n",
    "    #next_term_expiration = date(2024, 3, 31)\n",
    "\n",
    "    # Calculate time remaining until expiration in years\n",
    "    #today = date.today()\n",
    "    #time_to_near_term = (near_term_expiration - today).days / 365\n",
    "    #time_to_next_term = (next_term_expiration - today).days / 365\n",
    "\n",
    "    time_to_near_term = minutes_to_expiration[0]\n",
    "    time_to_next_term = minutes_to_expiration[1]\n",
    "    #time_to_near_term = 34,484\n",
    "    #time_to_next_term = 44,954\n",
    "\n",
    "    # Calculate interpolated/extrapolated yields using cubic spline\n",
    "    yield_R1 = cs(time_to_near_term)\n",
    "    yield_R2 = cs(time_to_next_term)\n",
    "    # print(f\"R1 (BEY) for {time_to_near_term} minutes: {yield_R1}\")\n",
    "    # print(f\"R2 (BEY) for {time_to_next_term} minutes: {yield_R2}\")\n",
    "\n",
    "    # Convert BEY to APY using the correct formula\n",
    "    APY_R1 = ((1 + yield_R1 / 2) ** 2) - 1\n",
    "    APY_R2 = ((1 + yield_R2 / 2) ** 2) - 1\n",
    "\n",
    "    r_near = np.log(1 + APY_R1)\n",
    "    r_next = np.log(1 + APY_R2)\n",
    "\n",
    "    # print(f\"R1 (APY) for {time_to_near_term} minutes: {APY_R1}\")\n",
    "    # print(f\"R2 (APY) for {time_to_next_term} minutes: {APY_R2}\")\n",
    "\n",
    "    # print(f\"R1 (ln(APY+1)) for {time_to_near_term} minutes: {r_near}\")\n",
    "    # print(f\"R2 (ln(APY+1)) for {time_to_next_term} minutes: {r_next}\")\n",
    "\n",
    "    # return [APY_R1, APY_R2]\n",
    "    # return [r_near, r_next]\n",
    "    return [yield_R1, yield_R2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_strike_diff(df):\n",
    "    # Create a new column 'strike_prev' that contains the previous 'strike' values\n",
    "    df['strike_prev'] = df['strike'].shift(-1)\n",
    "\n",
    "    # Create a new column 'strike_next' that contains the next 'strike' values\n",
    "    df['strike_next'] = df['strike'].shift(1)\n",
    "\n",
    "    # Create a new column 'strike_diff' that contains the differences between 'strike_next' and 'strike_prev'\n",
    "    df['strike_diff'] = (df['strike_prev'] - df['strike_next'])/2\n",
    "\n",
    "    # For the first and last 'strike', keep the original 'strike' values\n",
    "    # df.loc[0, 'strike_diff'] = df.loc[1, 'strike'] - df.loc[0, 'strike']\n",
    "    df.iloc[0, df.columns.get_loc('strike_diff')] = df.iloc[1, df.columns.get_loc('strike')] - \\\n",
    "        df.iloc[0, df.columns.get_loc('strike')]\n",
    "\n",
    "    df.iloc[-1, df.columns.get_loc('strike_diff')] = df.iloc[-1, df.columns.get_loc('strike')] -\\\n",
    "        df.iloc[-2, df.columns.get_loc('strike')]\n",
    "    # df.loc[df.index[-1], 'strike_diff'] = df.loc[df.index[-1],\n",
    "    #                                              'strike'] - df.loc[df.index[-2], 'strike']\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_strikes(df, option_type = None):\n",
    "    # Create new columns that contain the 'bid' values of the preceding and following rows\n",
    "    df['bid_prev1'] = df['bid'].shift(1)\n",
    "    df['bid_next1'] = df['bid'].shift(-1)\n",
    "\n",
    "    # For 'Call' options, find the first index where 'bid' and 'bid_next1' are 0\n",
    "    if option_type == 'Call' or df['option_type'].isin(['C', 'Call']).any():\n",
    "        try:\n",
    "            index_to_drop = df[(df['bid'] == 0) & (\n",
    "                df['bid_next1'] == 0)].index[0]\n",
    "            # Drop all rows from 'index_to_drop' to the end of the DataFrame\n",
    "            df = df.loc[:index_to_drop-1]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        except KeyError as e:\n",
    "        # Log the state of the DataFrame when the error occurs\n",
    "            logger.info(f\"Error: {e}\")\n",
    "            logger.info(f\"DataFrame state: {df.to_string()}\")\n",
    "            logger.info(f\"index_to_drop: {index_to_drop}\")\n",
    "            logger.info(f\"last_index: {last_index}\")\n",
    "            #print(f\"Error: {e}\")\n",
    "            #print(f\"DataFrame state: {df.to_string()}\")\n",
    "            print(f\"index_to_drop: {index_to_drop}\")\n",
    "            print(f\"last_index: {last_index}\")\n",
    "\n",
    "    # For 'Put' options, find the first index where 'bid' and 'bid_prev1' are 0\n",
    "    elif option_type == 'Put' or df['option_type'].isin(['P', 'Put']).any():\n",
    "        try:\n",
    "            index_to_drop = df[(df['bid'] == 0) & (\n",
    "                df['bid_prev1'] == 0)].index[0]\n",
    "            # Drop all rows from the start of the DataFrame to 'index_to_drop'\n",
    "            last_index = df.index[-1]\n",
    "            if index_to_drop < last_index:\n",
    "                df = df.loc[index_to_drop+1:]\n",
    "            else:\n",
    "                df = df.loc[:last_index]\n",
    "            #df = df.loc[index_to_drop+1:]\n",
    "        except IndexError:\n",
    "            pass\n",
    "        except KeyError as e:\n",
    "        # Log the state of the DataFrame when the error occurs\n",
    "            logger.info(f\"Error: {e}\")\n",
    "            logger.info(f\"DataFrame state: {df.to_string()}\")\n",
    "            logger.info(f\"index_to_drop: {index_to_drop}\")\n",
    "            logger.info(f\"last_index: {last_index}\")\n",
    "            #print(f\"Error: {e}\")\n",
    "            #print(f\"DataFrame state: {df.to_string()}\")\n",
    "            print(f\"index_to_drop: {index_to_drop}\")\n",
    "            print(f\"last_index: {last_index}\")\n",
    "\n",
    "    # Drop the 'bid_prev1' and 'bid_next1' columns\n",
    "    df = df.drop(columns=['bid_prev1', 'bid_next1'])\n",
    "\n",
    "    # remove any row that has zeor bid\n",
    "    df = df[df['bid'] != 0]\n",
    "\n",
    "    ####display(HTML(df.to_html(index=False, border=0)))\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_and_atm(min_diff_strike, df_calls, df_puts, activation, near_term):\n",
    "    \"\"\"\n",
    "    Calculate forward VIX by extraploating minimum strike price...\n",
    "    \"\"\"\n",
    "    df_calls_copy = df_calls.copy().set_index('strike', inplace=False)\n",
    "    df_puts_copy = df_puts.copy().set_index('strike', inplace=False)\n",
    "\n",
    "    forward = min_diff_strike + \\\n",
    "        activation * (df_calls.loc[df_calls['strike'] == min_diff_strike, 'mid-quote'].values[0] -\n",
    "                      df_puts.loc[df_puts['strike'] == min_diff_strike, 'mid-quote'].values[0])\n",
    "\n",
    "    print(\"Forward: \", forward)\n",
    "    common_strikes = df_calls_copy.index.intersection(df_puts_copy.index)\n",
    "\n",
    "    lower_strikes = common_strikes[common_strikes < forward]\n",
    "    atm_strike = lower_strikes.max()\n",
    "\n",
    "    #atm_strike = df_calls[df_calls['strike'] < f_near]['strike'].max()\n",
    "\n",
    "    row_calls = df_calls.loc[df_calls['strike']\n",
    "                             == atm_strike].reset_index(drop=True)\n",
    "    row_puts = df_puts.loc[df_puts['strike']\n",
    "                           == atm_strike].reset_index(drop=True)\n",
    "    average_values = (row_calls[['mid-quote', 'bid', 'ask', 'px_last']] +\n",
    "                      row_puts[['mid-quote', 'bid', 'ask', 'px_last']]) / 2\n",
    "    average_values['strike'] = atm_strike\n",
    "    average_values['option_type'] = 'ATM Avg Put/Call'\n",
    "    atm_df = average_values[['strike', 'bid', 'ask',\n",
    "                             'option_type', 'px_last', 'mid-quote']]\n",
    "\n",
    "    #display(HTML(atm_df.to_html(index=False, border=0)))\n",
    "    return forward, atm_df, atm_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_diff_strike(df_calls, df_puts):\n",
    "    # Set the strike price as the index in both dataframes\n",
    "    df_calls_copy = df_calls.copy()\n",
    "    df_puts_copy = df_puts.copy()\n",
    "\n",
    "    df_calls_copy.set_index('strike', inplace=True)\n",
    "    df_puts_copy.set_index('strike', inplace=True)\n",
    "\n",
    "    # Calculate the difference between the mid-quote values\n",
    "\n",
    "    mid_quote_diff = (df_calls_copy['mid-quote'] -\n",
    "                      df_puts_copy['mid-quote']).abs()\n",
    "\n",
    "    # Find the strike price with the minimum difference\n",
    "    try:\n",
    "        min_diff_strike = mid_quote_diff.idxmin()\n",
    "    except ValueError:\n",
    "        logger.error(\"Attempted to get argmin of an empty sequence.\")\n",
    "        logger.error(f\"mid_quote_diff: {mid_quote_diff}\")\n",
    "        logger.error(f\"df_calls_copy: {df_calls_copy} df_puts_copy: {df_puts_copy}\")\n",
    "        min_diff_strike = None\n",
    "\n",
    "    custom_print(\"min_diff_strike: \", min_diff_strike)\n",
    "    return min_diff_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_min_diff_strike_new(df_calls, df_puts, activation, near_term):\n",
    "\n",
    "    ##display(HTML(df_puts.to_html(index=False, border=0)))\n",
    "    ##display(HTML(df_calls.to_html(index=False, border=0)))\n",
    "\n",
    "    # Set the strike price as the index in both dataframes\n",
    "    df_calls_local = df_calls.copy()\n",
    "    df_puts_local = df_puts.copy()\n",
    "\n",
    "    df_calls_local['strike-copy'] = df_calls_local['strike']\n",
    "    df_puts_local['strike-copy'] = df_puts_local['strike']\n",
    "\n",
    "    df_calls_local.set_index('strike', inplace=True)\n",
    "    df_puts_local.set_index('strike', inplace=True)\n",
    "\n",
    "    # Find common strikes\n",
    "    common_strikes = df_calls_local.index.intersection(df_puts_local.index)\n",
    "\n",
    "    # Filter dataframes to only include common strikes\n",
    "    df_calls_local = df_calls_local.loc[common_strikes]\n",
    "    df_puts_local = df_puts_local.loc[common_strikes]\n",
    "\n",
    "    # Filter out rows where mid-quote is zero in both dataframes\n",
    "    non_zero_mask = ~((df_calls_local['mid-quote'] == 0)\n",
    "                      & (df_puts_local['mid-quote'] == 0))\n",
    "    df_calls_local = df_calls_local[non_zero_mask]\n",
    "    df_puts_local = df_puts_local[non_zero_mask]\n",
    "\n",
    "    # Calculate the difference between the mid-quote values\n",
    "    mid_quote_diff = (\n",
    "        df_calls_local['mid-quote'] - df_puts_local['mid-quote']).abs()\n",
    "\n",
    "    # Find the strike price with the minimum difference\n",
    "    try:\n",
    "        min_diff_strike = mid_quote_diff.idxmin()\n",
    "    except ValueError:\n",
    "        logger.error(\"Attempted to get argmin of an empty sequence.\")\n",
    "        logger.error(f\"mid_quote_diff: {mid_quote_diff}\")\n",
    "        logger.error(f\"df_calls_copy: {df_calls_copy} df_puts_copy: {df_puts_copy}\")\n",
    "        min_diff_strike = None    \n",
    "    custom_print(\"min_diff_strike: \", min_diff_strike)\n",
    "\n",
    "    #######################################################################################\n",
    "    forward = min_diff_strike + \\\n",
    "        activation * (df_calls.loc[df_calls['strike'] == min_diff_strike, 'mid-quote'].values[0] -\n",
    "                      df_puts.loc[df_puts['strike'] == min_diff_strike, 'mid-quote'].values[0])\n",
    "\n",
    "    custom_print(\"Forward: \", forward)\n",
    "\n",
    "    atm_strike_another = df_calls_local.loc[df_calls_local['strike-copy']\n",
    "                                            < forward, 'strike-copy'].max()\n",
    "    custom_print(\"atm_strike-another: \", atm_strike_another)\n",
    "\n",
    "    atm_strike = df_calls_local[df_calls_local['strike-copy']\n",
    "                                < forward]['strike-copy'].max()\n",
    "\n",
    "    custom_print(\"atm_strike: \", atm_strike)\n",
    "    ###display(HTML(df_calls_local.to_html(index=False, border=0)))\n",
    "    ###display(HTML(df_puts_local.to_html(index=False, border=0)))\n",
    "\n",
    "    row_calls = df_calls.loc[df_calls['strike']\n",
    "                             == atm_strike].reset_index(drop=True)\n",
    "    row_puts = df_puts.loc[df_puts['strike']\n",
    "                           == atm_strike].reset_index(drop=True)\n",
    "    average_values = (row_calls[['mid-quote', 'bid', 'ask', 'px_last']] +\n",
    "                      row_puts[['mid-quote', 'bid', 'ask', 'px_last']]) / 2\n",
    "    average_values['strike'] = atm_strike\n",
    "    average_values['option_type'] = 'ATM Avg Put/Call'\n",
    "    atm_df = average_values[['strike', 'bid', 'ask',\n",
    "                             'option_type', 'px_last', 'mid-quote']]\n",
    "\n",
    "    #######display(HTML(atm_df.to_html(index=False, border=0)))\n",
    "    return forward, atm_df, atm_strike\n",
    "    ##############################################################################################\n",
    "\n",
    "    # return min_diff_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preapare_data(df):\n",
    "    df = df.fillna(0)\n",
    "    # Split the dataframe into calls and puts\n",
    "    df_calls = df[df['option_type'] == 'C'].copy()\n",
    "    df_puts = df[df['option_type'] == 'P'].copy()\n",
    "\n",
    "    df_puts.loc[:, 'mid-quote'] = (df_puts['bid'] + df_puts['ask']) / 2\n",
    "    df_calls.loc[:, 'mid-quote'] = (df_calls['bid'] + df_calls['ask']) / 2\n",
    "\n",
    "    return df_calls, df_puts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "\n",
    "def chain_of_responsibility(df, r, t, near_term=True):\n",
    "\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    df_calls, df_puts = preapare_data(df)\n",
    "\n",
    "    # Remove the strikes with no bid price\n",
    "    df_puts, df_calls = [remove_strikes(\n",
    "        df_puts, 'Put'), remove_strikes(df_calls, 'Call')]\n",
    "\n",
    "    # if near_term is False:\n",
    "    #     display(HTML(df_puts.to_html(index=False, border=0)))\n",
    "    #     display(HTML(df_calls.to_html(index=False, border=0)))\n",
    "\n",
    "    # Find the min strike difference\n",
    "    ######min_diff_strike = find_min_diff_strike_new(df_calls, df_puts, near_term)\n",
    "\n",
    "    ###########################\n",
    "    activation = np.exp(r*t)\n",
    "    forward, df_atm, atm_strike = find_min_diff_strike_new(\n",
    "        df_calls, df_puts, activation, near_term)\n",
    "    ##########################\n",
    "\n",
    "    ####print(forward, df_atm, atm_strike)\n",
    "\n",
    "    # Calculate Forwrard\n",
    "    # activation = np.exp(r*t)\n",
    "    # forward, df_atm, atm_strike = forward_and_atm(\n",
    "    #     min_diff_strike, df_calls.copy(), df_puts.copy(), activation, near_term)\n",
    "\n",
    "    # activation = np.exp(r*t)\n",
    "    # forward, df_atm, atm_strike = calculate_forward(\n",
    "    #     min_diff_strike, df_calls, df_puts, activation, near_term)\n",
    "\n",
    "    # Filter the dataframe to include only OTM strike\n",
    "    df_puts = df_puts[df_puts['strike'] < atm_strike]\n",
    "    df_calls = df_calls[df_calls['strike'] > atm_strike]\n",
    "\n",
    "    # Remove the strikes with no bid price\n",
    "    df_puts, df_calls = [remove_strikes(df_puts, 'Put'), remove_strikes(df_calls, 'Call')]\n",
    "\n",
    "    # Combine data frames\n",
    "    df_otm = pd.concat([df_puts, df_atm, df_calls], ignore_index=True)\n",
    "    df_otm = df_otm.sort_values('strike')\n",
    "\n",
    "    # Add adjescent strike difference\n",
    "    df_otm = add_strike_diff(df_otm)\n",
    "\n",
    "    # Contribution per Strike\n",
    "    df_otm['strike_squared'] = df_otm['strike'] ** 2\n",
    "    df_otm['strike_contribution'] = (df_otm['strike_diff'] * df_otm['mid-quote'] * activation)/df_otm['strike_squared']\n",
    "\n",
    "    #display(HTML(df_otm.to_html(index=False, border=0)))\n",
    "    total_contribution = 2 * df_otm['strike_contribution'].sum()/t\n",
    "    #print(\"Total contribution\", total_contribution)\n",
    "    decay = ((forward/atm_strike - 1) ** 2)/t\n",
    "\n",
    "    sigma_squared = (total_contribution - decay)\n",
    "    ################################Per strike Quantity Contribution####################################\n",
    "    df_otm['per_strike_qunatity_contribution'] = (df_otm['strike_diff'] * activation)/df_otm['strike_squared']\n",
    "    df_otm['per_strike_quantity_term_adjustment'] = (2 * df_otm['per_strike_qunatity_contribution'])/t\n",
    "    ###################################################################################################\n",
    "    \n",
    "    ######print(\"Sigma squared\", sigma_squared)\n",
    "    #display(HTML(df_otm.to_html(index=False, border=0)))\n",
    "\n",
    "    return sigma_squared, df_otm, atm_strike\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def create_dataset_from_data_stream(instrument_type, req_type, sec, start_date, end_date, expiry_date, ivl):\n",
    "    # Define the base URL\n",
    "    base_url = \"http://127.0.0.1:25510/bulk_at_time\"\n",
    "\n",
    "    # Construct the request URL\n",
    "    request_url = f\"{base_url}/{instrument_type}/{req_type}\"\n",
    "\n",
    "    # Define the query parameters\n",
    "    params = {\n",
    "        \"end_date\": end_date,\n",
    "        \"exp\": expiry_date,\n",
    "        \"ivl\": ivl,\n",
    "        \"root\": sec,\n",
    "        \"start_date\": start_date\n",
    "    }\n",
    "\n",
    "    # Send the request\n",
    "    response = requests.get(request_url, params=params)\n",
    "    data = json.loads(response.text)\n",
    "    df = pd.json_normalize(data['response'])\n",
    "    tick_columns = [\"ms_of_day\", \"bid_size\", \"bid_exchange\", \"bid\", \"bid_condition\", \"ask_size\", \"ask_exchange\", \"ask\", \"ask_condition\", \"date\"]\n",
    "    try:\n",
    "        df[tick_columns] = df['ticks'].apply(lambda x: pd.Series(x[0]))\n",
    "        df['strike'] = df['contract.strike']/1000\n",
    "        df.sort_values(by=['strike'], inplace=True)\n",
    "        df = df.rename(columns={'contract.right': 'option_type'})\n",
    "        working_set = df[['strike', 'bid', 'ask', 'option_type']].copy()\n",
    "        working_set.loc[:, 'px_last'] = 999\n",
    "        ###working_set['px_last'] = 999\n",
    "        \n",
    "\n",
    "    except Exception as e:\n",
    "        # Log the error message and the program state\n",
    "        logger.error(f\"Failed to fetch {response.url} on {start_date}\")\n",
    "        urls_with_error.append(f\"Failed to fetch {response.url} on {start_date}\")\n",
    "        logger.error(f\"Error: {str(e)}\")\n",
    "        logger.error(f\"Expiry date: {expiry_date}\")\n",
    "        logger.error(f\"Start date: {start_date}\")\n",
    "        logger.error(f\"Program state: {df}\")\n",
    "        return None, response.url\n",
    "        \n",
    "\n",
    "    #working_set.to_csv('./historical/output.csv', index=False)\n",
    "    #working_set.to_json('./historical/output.json', index=False)\n",
    "    #display(HTML(working_set.to_html(index=False, border=0)))\n",
    "\n",
    "    # Return the response\n",
    "    return working_set\n",
    "\n",
    "urls_with_error = []\n",
    "trade_date, end_date, expiry_date = '20230214', '20230214', '20230215' \n",
    "#working_set = create_dataset_from_data_stream('option', 'quote', 'SPXW', trade_date, end_date, expiry_date, 57675000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# Time to expiration\n",
    "import vix_utils\n",
    "\n",
    "def spawn_backtest(vix_future_settlement_date, calc_date, run_on_data_stream = True, existing_df_near=None, existing_df_next=None):\n",
    "    eod = {\n",
    "        \"year\": vix_future_settlement_date.year,\n",
    "        \"month\": vix_future_settlement_date.month,\n",
    "        \"day\": vix_future_settlement_date.day,\n",
    "        \"hour\": 16,\n",
    "        \"minute\": 15,\n",
    "        \"second\": 0\n",
    "    }\n",
    "\n",
    "    ###run_on_data_stream = True\n",
    "\n",
    "    delta = abs(datetime.datetime.now() - calc_date)\n",
    "    ####print(f\"Time delta : {delta} \")\n",
    "    custom_print(\"delta: \", delta)\n",
    "\n",
    "\n",
    "    l_t1, l_t2 = chicago_eod_four_PM(\n",
    "        eod, near_term=True), chicago_eod_four_PM(eod, near_term=False)\n",
    "\n",
    "    start_date = calc_date.strftime('%Y%m%d')\n",
    "    end_date =   calc_date.strftime('%Y%m%d')\n",
    "\n",
    "    option_expiry_near = l_t1[1].strftime('%Y%m%d')\n",
    "    option_expiry_next = l_t2[1].strftime('%Y%m%d')\n",
    "    \n",
    "    forward_days = (vix_future_settlement_date - calc_date).days * 1440\n",
    "\n",
    "    n_t1 = l_t1[0] + forward_days\n",
    "    n_t2 = l_t2[0] + forward_days\n",
    "\n",
    "    ####print(f\"n_t1 and n_t2 {n_t1} {n_t2} \")\n",
    "\n",
    "    # extrapolated rates to expiration\n",
    "    r_near, r_next = np.array(cubic_spline_risk_free_rate(\n",
    "        [n_t1, n_t2], days = delta))/100\n",
    "    custom_print(\"r_near and r_next\", r_near, r_next, )\n",
    "    custom_print(f\"start_date : {start_date}, end_date : {end_date}, option_expiry_near : {option_expiry_near}, option_expiry_next : {option_expiry_next}\")\n",
    "    print(f\"start_date : {start_date}, end_date : {end_date}, option_expiry_near : {option_expiry_near}, option_expiry_next : {option_expiry_next}\")\n",
    "    t_near = n_t1/525600\n",
    "    t_next = n_t2/525600\n",
    "\n",
    "    if(run_on_data_stream == True):\n",
    "        if existing_df_near is None or existing_df_next is None:\n",
    "\n",
    "            df_near = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = start_date, \n",
    "                                                    end_date = start_date, expiry_date = option_expiry_near, ivl = 57675000)\n",
    "            df_next = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = start_date, \n",
    "                                                    end_date = start_date, expiry_date = option_expiry_next, ivl = 57675000)\n",
    "        else:\n",
    "            df_near = existing_df_near\n",
    "            df_next = existing_df_next\n",
    "        \n",
    "        if df_near is None or df_next is None:\n",
    "            error_urls.append(error_url)\n",
    "            return None\n",
    "    else:\n",
    "        df_near = pd.read_csv('./dataset/dataset_20230317__atm_plus_1.csv')\n",
    "        df_next = pd.read_csv('./dataset/dataset_20230324__atm_plus_1.csv')\n",
    "\n",
    "\n",
    "    sigma_squared_near, df_vix_near, atm_near = chain_of_responsibility(df_near, r_near, t_near) \n",
    "    sigma_squared_next, df_vix_next, atm_next = chain_of_responsibility(df_next, r_next, t_next, False)\n",
    "    \n",
    "    atm_near_details = df_vix_near.loc[df_vix_near['strike'] == atm_near]\n",
    "    atm_next_details = df_vix_next.loc[df_vix_next['strike'] == atm_next]                                        \n",
    "\n",
    "    custom_print(\"Sigma squared near\", sigma_squared_near)\n",
    "    custom_print(\"Sigma squared next\", sigma_squared_next)\n",
    "\n",
    "    n_30 = 43200 + forward_days\n",
    "    n_365 = 525600\n",
    "    n_y_m = n_365/n_30\n",
    "\n",
    "    tnear_sig_squared = sigma_squared_near * t_near\n",
    "    tnext_sig_squared = sigma_squared_next * t_next\n",
    "\n",
    "\n",
    "    near_dev = tnear_sig_squared * ((n_t2 - n_30)/(n_t2 - n_t1))\n",
    "    next_dev = tnext_sig_squared * ((n_30 - n_t1)/(n_t2 - n_t1))\n",
    "    tot_dev = near_dev + next_dev\n",
    "    vix = np.sqrt(tot_dev * n_y_m) * 100\n",
    "\n",
    "    print(f'Vix Forward on {start_date} - {vix}')\n",
    "    #######print(f'atm_near - {atm_near}')\n",
    "    ########print(f'atm_next - {atm_next}')\n",
    "    \n",
    "    df_near['mid_quote'] = (df_near['bid'] + df_near['ask']) / 2\n",
    "    df_next['mid_quote'] = (df_next['bid'] + df_next['ask']) / 2\n",
    "    df_vix_near = df_vix_near.rename(columns={'mid-quote': 'mid_quote'})\n",
    "    df_vix_next = df_vix_next.rename(columns={'mid-quote': 'mid_quote'})\n",
    "\n",
    "    ################################################\n",
    "    df_vix_near['T1'] = t_near\n",
    "    df_vix_near['(M_t2 - M_30)/(M_t2 - M_t1)'] = (n_t2 - n_30)/(n_t2 - n_t1)\n",
    "    df_vix_near['M_365/M_30'] = n_y_m\n",
    "    \n",
    "    df_vix_near['per_strike_constants'] = df_vix_near['per_strike_quantity_term_adjustment'] * n_y_m * t_near * (n_t2 - n_30)/(n_t2 - n_t1)\n",
    "\n",
    "    df_vix_next['T2'] = t_next\n",
    "    df_vix_next['(M_30 - M_t1)/(M_t2 - M_t1)'] = (n_30 - n_t1)/(n_t2 - n_t1)\n",
    "    df_vix_next['M_365/M_30'] = n_y_m\n",
    "\n",
    "    df_vix_next['per_strike_constants'] = df_vix_next['per_strike_quantity_term_adjustment'] * n_y_m * t_next * (n_30 - n_t1)/(n_t2 - n_t1)\n",
    "\n",
    "    ###############################################\n",
    "\n",
    "    \n",
    "\n",
    "    return vix, df_near, df_next, df_vix_near, df_vix_next, option_expiry_near, option_expiry_next\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_df_to_csv(df, path):\n",
    "    # Extract directory from the path\n",
    "    dir_path = os.path.dirname(path)\n",
    "\n",
    "    # Check if the directory exists\n",
    "    if not os.path.exists(dir_path):\n",
    "        # If the directory doesn't exist, create it\n",
    "        os.makedirs(dir_path)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(path, index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def create_directory_structure(trade_date):\n",
    "    # Define the directories to be created\n",
    "    directories = [\n",
    "        f'./result-set/{trade_date}',\n",
    "        f'./result-set/{trade_date}/future',\n",
    "        f'./result-set/{trade_date}/future/abridged',\n",
    "        f'./result-set/{trade_date}/P&L',\n",
    "        f'./result-set/{trade_date}/P&L/Delta-25&Above',\n",
    "        f'./result-set/{trade_date}/spot'\n",
    "        './result-set/P&L-across-days',\n",
    "        './result-set/P&L-across-days/abridged'\n",
    "\n",
    "        \n",
    "    ]\n",
    "\n",
    "    # Iterate over the directories\n",
    "    for directory in directories:\n",
    "        # Check if the directory does not already exist\n",
    "        if not os.path.exists(directory):\n",
    "            # Create the directory\n",
    "            os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def calculate_quantity_per_strike(row, vix_index):\n",
    "    # Calculate the quantity per strike\n",
    "    q  = (10000 *row.per_strike_constants)/(2*vix_index) \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_price_new(row, df2):\n",
    "    if row['option_type'] == 'ATM Avg Put/Call':\n",
    "        matching_rows = df2[df2['strike'] == row['strike']]\n",
    "        if not matching_rows.empty:\n",
    "            future_price = matching_rows['mid_quote'].mean()\n",
    "            pl = row['quantity'] * (future_price - row['mid_quote'])\n",
    "            return pd.Series([future_price, pl])\n",
    "    else:\n",
    "        matching_row = df2[(df2['strike'] == row['strike']) & (df2['option_type'] == row['option_type'])]\n",
    "        if not matching_row.empty:\n",
    "            future_price = matching_row['mid_quote'].values[0]\n",
    "            pl = row['quantity'] * (future_price - row['mid_quote'])\n",
    "            return pd.Series([future_price, pl])\n",
    "    return pd.Series([None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vix_utils, logging, asyncio\n",
    "import pandas as pd\n",
    "\n",
    "vix_futures,vix_cash=await asyncio.gather(vix_utils.async_load_vix_term_structure(),vix_utils.async_get_vix_index_histories())\n",
    "\n",
    "def vix_futures_calc(trade_date, settlement_date):\n",
    "    filtered_df = vix_futures[(vix_futures['Trade Date'] == trade_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "    settlement_df = vix_futures[(vix_futures['Trade Date'] == settlement_date) & (vix_futures['Tenor_Monthly'] == 1.0)]\n",
    "    if not filtered_df.empty:\n",
    "        vix_futures_on_trade_day = filtered_df['Close'].values[0]\n",
    "        vix_futures_on_settlement_day = settlement_df['Close'].values[0]\n",
    "        return vix_futures_on_trade_day, vix_futures_on_settlement_day    \n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mibian\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def calc_implied_vol_delta_and_parity(row, underlying_price, days_to_expiry):\n",
    "    interest_rate = 0.046\n",
    "    delta_type = {'C': 'callDelta', 'P': 'putDelta', 'ATM Avg Put/Call': 'putDelta'}\n",
    "\n",
    "    def calculate_mibian_bs(call_price, put_price, implied_vol=None):\n",
    "        if implied_vol is None:\n",
    "            ###print(f'Call Price: {call_price}, Put Price: {put_price}')\n",
    "            c = mibian.BS([underlying_price, row['strike'], interest_rate, days_to_expiry], callPrice=call_price, putPrice=put_price)\n",
    "            implied_vol = c.impliedVolatility\n",
    "        c = mibian.BS([underlying_price, row['strike'], interest_rate, days_to_expiry], volatility=implied_vol)\n",
    "        delta = getattr(c, delta_type[row['option_type']])\n",
    "        return implied_vol, delta\n",
    "\n",
    "    call_price, put_price = (row['mid_quote'], None) if row['option_type'] == 'C' else (None, row['mid_quote'])\n",
    "    implied_vol, delta = calculate_mibian_bs(call_price, put_price)\n",
    "\n",
    "\n",
    "    return pd.Series([implied_vol, delta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_atm_df(df):\n",
    "\n",
    "    # Find the row where option_type is 'ATM Avg Put/Call'\n",
    "    atm_avg_put_call_row = df[df['option_type'] == 'ATM Avg Put/Call']\n",
    "\n",
    "    # Get the strike value from this row\n",
    "    atm_avg_put_call_strike = atm_avg_put_call_row['strike'].values[0]\n",
    "\n",
    "    # Find the rows in df where strike matches atm_avg_put_call_strike\n",
    "    matching_rows = df[df['strike'] == atm_avg_put_call_strike]\n",
    "\n",
    "    # Exclude the 'ATM Avg Put/Call' row from matching_rows\n",
    "    new_df = matching_rows[matching_rows['option_type'] != 'ATM Avg Put/Call']\n",
    "    \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_delta_across_terms(df, bound = 0.25):\n",
    "\n",
    "    def find_unique_closest_strikes(df, option_type, target_deltas):\n",
    "        \"\"\"\n",
    "        Finds unique closest strikes for given target deltas for the specified option type.\n",
    "        \"\"\"\n",
    "        filtered_df = df[df['option_type'] == option_type]\n",
    "        selected_strikes = pd.DataFrame()\n",
    "\n",
    "        for delta in target_deltas:\n",
    "            # Adjust for negative delta in case of Puts\n",
    "            adjusted_delta = -abs(delta) if option_type == 'P' else abs(delta)\n",
    "\n",
    "            # Exclude already selected strikes\n",
    "            available_df = filtered_df[~filtered_df.index.isin(selected_strikes.index)]\n",
    "\n",
    "            # Find the closest strike\n",
    "            closest_idx = (available_df['delta'] - adjusted_delta).abs().idxmin()\n",
    "            selected_strikes = pd.concat([selected_strikes, available_df.loc[[closest_idx]]])\n",
    "\n",
    "        return selected_strikes\n",
    "\n",
    "    target_deltas = [0.1, 0.25]\n",
    "    atm_df = construct_atm_df(df)\n",
    "\n",
    "\n",
    "    # Apply the function for Calls and Puts\n",
    "    closest_strikes_calls = find_unique_closest_strikes(df, 'C', target_deltas)\n",
    "    closest_strikes_puts = find_unique_closest_strikes(df, 'P', target_deltas)\n",
    "\n",
    "    # Combine results\n",
    "    closest_strikes = pd.concat([closest_strikes_calls, closest_strikes_puts])\n",
    "    candidate_df = pd.concat([closest_strikes, atm_df])\n",
    "\n",
    "    ##display(HTML(candidate_df.to_html(index=False, border=0)))\n",
    "    return candidate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_left_overs_for_future_ref(df_final, df_near):\n",
    "\n",
    "    filtered_df_near = df_final[df_final['option_type'] == 'ATM Avg Put/Call']\n",
    "    filtered_df_near = filtered_df_near.rename(columns={'mid_quote': 'mid_quote_filtered', 'option_type': 'option_type_filtered'})\n",
    "\n",
    "    matching_strikes_df_near = df_near[df_near['strike'].isin(filtered_df_near['strike'])]\n",
    "    \n",
    "    # Drop overlapping columns from filtered_df_near\n",
    "    overlapping_columns = [col for col in filtered_df_near.columns if col in matching_strikes_df_near.columns and col != 'strike']\n",
    "    filtered_df_near = filtered_df_near.drop(columns=overlapping_columns)\n",
    "    df_final['px_last'] = 999\n",
    "\n",
    "    # Merge matching_strikes_df_near and filtered_df_near\n",
    "    merged_df = pd.merge(matching_strikes_df_near, filtered_df_near, on='strike', how='left')\n",
    "    merged_df.drop(columns=['mid_quote_filtered', 'option_type_filtered'], inplace=True)\n",
    "\n",
    "    # Check if columns are the same in df_final and merged_df\n",
    "    if set(df_final.columns) != set(merged_df.columns):\n",
    "        print(\"missing clumns merged_df: \", set(df_final.columns) - set(merged_df.columns))\n",
    "        print(\"missing clumns df_final: \", set(merged_df.columns) - set(df_final.columns))\n",
    "        raise ValueError(\"Columns in df_final and merged_df are not the same\")\n",
    "\n",
    "    # Append merged_df to df_final\n",
    "    df_final = pd.concat([df_final, merged_df], ignore_index=True)\n",
    "\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_vol_and_delta(df, trade_date, expiry_date):\n",
    "    #####days_to_expiry = (datetime.datetime.strptime(expiry_date, \"%Y%m%d\") - datetime.datetime.strptime(trade_date, \"%Y-%m-%d\")).days\n",
    "    \n",
    "    days_to_expiry = (datetime.datetime.strptime(expiry_date, \"%Y%m%d\") - datetime.datetime.strptime(trade_date, \"%Y%m%d\")).days\n",
    "    forward = df[df['option_type'] == 'ATM Avg Put/Call']['strike'].values[0]\n",
    "    df[['Implied Vol', 'delta']] = df.apply(calc_implied_vol_delta_and_parity, args=(forward, days_to_expiry), axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_quantity_prices_other_details(df_near, df_next, df_settlement_near, df_settlement_next, tuple_vix, tuple_vix_futures):\n",
    "    \n",
    "    df_near['quantity'] = df_near.apply(calculate_quantity_per_strike, axis=1, args=(tuple_vix[1],))\n",
    "    df_next['quantity'] = df_next.apply(calculate_quantity_per_strike, axis=1, args=(tuple_vix[1],))\n",
    "\n",
    "    df_near[['settlement_day_prices', 'per_strike_P&L']] = df_near.apply(get_future_price_new, args=(df_settlement_near,), axis=1)\n",
    "    df_next[['settlement_day_prices', 'per_strike_P&L']] = df_next.apply(get_future_price_new, args=(df_settlement_next,), axis=1)\n",
    "    \n",
    "    df_near['vix_forward'], df_near['new_vix_forward'] = tuple_vix\n",
    "    df_next['vix_forward'], df_next['new_vix_forward'] = tuple_vix\n",
    "    \n",
    "    df_near['vix_futures_on_trade_date'],df_near['vix_futures_on_settlement_date'] = tuple_vix_futures\n",
    "    df_next['vix_futures_on_trade_date'],df_next['vix_futures_on_settlement_date'] = tuple_vix_futures\n",
    "\n",
    "    return df_near, df_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pl_for_the_day(vix, df_near, df_next):\n",
    "\n",
    "    vix_futures_on_trade_date = df_near['vix_futures_on_trade_date'].values[0]\n",
    "    vix_futures_on_settlement_date = df_near['vix_futures_on_settlement_date'].values[0]\n",
    "    \n",
    "    if vix_futures_on_trade_date > vix :\n",
    "\n",
    "        df_near['strategy']  = \"Buy Basket sell Futures\"\n",
    "        df_near['future_P&L'] = vix_futures_on_trade_date - vix_futures_on_settlement_date\n",
    "        ###df_near['P&L'] = (df_near['quantity'] * (df_near['settlement_day_prices'] - df_near['mid_quote'])).sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date)\n",
    "        #####df_near['P&L'] = df_near['per_strike_P&L'].sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date)\n",
    "        df_near['P&L'] = df_near['per_strike_P&L'].sum() + df_near['future_P&L'].iloc[0]\n",
    "            \n",
    "        df_next['strategy']  = \"Buy Basket sell Futures\"\n",
    "        df_next['future_P&L'] = vix_futures_on_trade_date - vix_futures_on_settlement_date\n",
    "        ###df_next['P&L'] = (df_next['quantity'] * (df_next['settlement_day_prices'] - df_next['mid_quote'])).sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date  )\n",
    "        ####df_next['P&L'] = df_next['per_strike_P&L'].sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date  )\n",
    "        df_next['P&L'] = df_next['per_strike_P&L'].sum() + df_next['future_P&L'].iloc[0]\n",
    "            \n",
    "    else:\n",
    "    \n",
    "        df_near['strategy']  = \"Buy Vix futures sell Basket\"\n",
    "        df_near['per_strike_P&L'] = df_near['per_strike_P&L'] * -1\n",
    "        df_near['future_P&L'] = vix_futures_on_settlement_date - vix_futures_on_trade_date\n",
    "        ###df_near['P&L'] = (df_near['quantity'] * (df_near['mid_quote'] - df_near['settlement_day_prices'])).sum() + (vix_futures_on_settlement_date - vix_futures_on_trade_date)\n",
    "        df_near['P&L'] = df_near['per_strike_P&L'].sum() + df_near['future_P&L'].iloc[0]\n",
    "        \n",
    "        \n",
    "        df_next['strategy']  = \"Buy Vix futures sell Basket\"\n",
    "        df_next['per_strike_P&L'] = df_next['per_strike_P&L'] * -1\n",
    "        df_next['future_P&L'] = vix_futures_on_settlement_date - vix_futures_on_trade_date\n",
    "        ###df_next['P&L'] = (df_next['quantity'] * (df_next['settlement_day_prices'] - df_next['mid_quote'])).sum() + (vix_futures_on_settlement_date - vix_futures_on_trade_date  )\n",
    "        df_next['P&L'] = df_next['per_strike_P&L'].sum() + df_next['future_P&L'].iloc[0]\n",
    "\n",
    "    combined_df = pd.concat([df_near, df_next], ignore_index=True)\n",
    "    #####We are adding Future P&L twice in the combined_df so subsctracting it once\n",
    "    combined_df['P&L'] = df_near['P&L'].iloc[0] + df_next['P&L'].iloc[0] - df_near['future_P&L'].iloc[0]\n",
    "    \n",
    "    ##### This is more correct way to calculate P&L  the other code is working so will not change as of now\n",
    "    #######combined_df['P&L'] = combined_df['per_strike_P&L'].sum()  + combined_df['future_P&L'].values[0]\n",
    "    \n",
    "    return df_near, df_next, combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_top_level_pl_df(combined_df, formatted_trade_date_str, basket_near_total, basket_next_total, vix):\n",
    "    \n",
    "    # Create a DataFrame with the top-level P&L information\n",
    "    basket_pl = combined_df['per_strike_P&L'].sum()\n",
    "    future_pl = combined_df['future_P&L'].values[0]\n",
    "    total_pl = basket_pl + future_pl\n",
    "    vix_forward = vix\n",
    "    vix_futures_on_trade_day = combined_df['vix_futures_on_trade_date'].values[0]\n",
    "    vix_futures_on_settlement_day = combined_df['vix_futures_on_settlement_date'].values[0]\n",
    "\n",
    "\n",
    "\n",
    "    df_summary = pd.DataFrame({\n",
    "                        'trade_date': [formatted_trade_date_str],\n",
    "                        'near-contribution': [basket_near_total],\n",
    "                        'next-contribution': [basket_next_total],\n",
    "                        'vix-forward': [vix_forward],\n",
    "                        'vix-futures-on-trade_day': [vix_futures_on_trade_day],\n",
    "                        'vix-futures-on-settlement_day': [vix_futures_on_settlement_day],\n",
    "                        'Basket-P&L': basket_pl,\n",
    "                        'Future-P&L': future_pl,\n",
    "                        'Total-P&L': total_pl \n",
    "                    })\n",
    "    \n",
    "    return df_summary\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replicating Vix future for 2023-02-15 on 2023-02-07 16:15:00\n",
      "start_date : 20230207, end_date : 20230207, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230207 - 19.793021206730558\n",
      "Vix futures on 2023-02-07 19.49 and 2023-02-15 18.9\n",
      "start_date : 20230207, end_date : 20230207, option_expiry_near : 20230317, option_expiry_next : 20230324\n",
      "Vix Forward on 20230207 - 18.89229031785105\n"
     ]
    }
   ],
   "source": [
    "###Backtesting for a single date\n",
    "import datetime\n",
    "\n",
    "def run_backtest(year, month, day):\n",
    "    try:\n",
    "        ins_type = \"future\"\n",
    "        \n",
    "        v = vix_utils.vix_futures_expiry_date_from_trade_date(year, month, day, 1) if ins_type == \"future\" else datetime.datetime(year, month, day)\n",
    "        on_day = datetime.datetime.combine(datetime.datetime(year, month, day), datetime.time(16, 15, 0))\n",
    "        formatted_trade_date_str = on_day.strftime(\"%Y%m%d\")\n",
    "        vix_future_settlement_day = datetime.datetime.combine(v, datetime.time())\n",
    "        print(f\"Replicating Vix {ins_type} for {v} on {on_day}\")\n",
    "        \n",
    "        create_directory_structure(on_day.strftime('%Y-%m-%d'))\n",
    "        vix, df_near, df_next, df_vix_near, df_vix_next, option_expiry_near, option_expiry_next= spawn_backtest(vix_future_settlement_day, on_day)\n",
    "        \n",
    "        #######################################################\n",
    "        df_per_strike_quantity_near = df_vix_near[['strike', 'option_type', 'bid', 'ask','mid_quote','per_strike_constants' ]].copy()\n",
    "        df_per_strike_quantity_next = df_vix_next[['strike', 'option_type', 'bid', 'ask','mid_quote', 'per_strike_constants']].copy()\n",
    "        \n",
    "        observation_date = on_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        df_per_strike_quantity_near['vix_forward'] = vix\n",
    "        df_per_strike_quantity_next['vix_forward'] = vix\n",
    "        df_per_strike_quantity_near['quantity'] = df_per_strike_quantity_near.apply(calculate_quantity_per_strike, axis=1, args=(vix,))\n",
    "        df_per_strike_quantity_next['quantity'] = df_per_strike_quantity_next.apply(calculate_quantity_per_strike, axis=1, args=(vix,))\n",
    "        \n",
    "        settlement_day_str = vix_future_settlement_day.date().strftime('%Y%m%d')\n",
    "\n",
    "        df_settlement_near = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = settlement_day_str, \n",
    "                                                end_date = settlement_day_str, expiry_date = option_expiry_near, ivl = 57675000)\n",
    "        df_settlement_next = create_dataset_from_data_stream(\"option\", \"quote\", \"SPXW\", start_date = settlement_day_str, \n",
    "                                                end_date = settlement_day_str, expiry_date = option_expiry_next, ivl = 57675000)\n",
    "        \n",
    "        df_settlement_near['mid_quote'] = (df_settlement_near['bid'] + df_settlement_near['ask']) / 2\n",
    "        df_settlement_next['mid_quote'] = (df_settlement_next['bid'] + df_settlement_next['ask']) / 2\n",
    "        \n",
    "        df_per_strike_quantity_near[['settlement_day_prices', 'per_strike_P&L']] = df_per_strike_quantity_near.apply(get_future_price_new, args=(df_settlement_near,), axis=1)\n",
    "        df_per_strike_quantity_next[['settlement_day_prices', 'per_strike_P&L']] = df_per_strike_quantity_next.apply(get_future_price_new, args=(df_settlement_next,), axis=1)\n",
    "\n",
    "        \n",
    "#####################################################################################################\n",
    "        vix_futures_on_trade_date, vix_futures_on_settlement_date = vix_futures_calc(on_day.date().strftime('%Y-%m-%d'), vix_future_settlement_day.date().strftime('%Y-%m-%d'))\n",
    "        print(f\"Vix futures on {on_day.date().strftime('%Y-%m-%d')} {vix_futures_on_trade_date} and {vix_future_settlement_day.date().strftime('%Y-%m-%d')} {vix_futures_on_settlement_date}\")\n",
    "        tuple_vix_futures = (vix_futures_on_trade_date, vix_futures_on_settlement_date)\n",
    "        # tuple_vix = (vix, vix)\n",
    "\n",
    "        # df_per_strike_quantity_near, df_per_strike_quantity_near =  populate_quantity_prices_other_details(df_per_strike_quantity_near, \n",
    "        #                                         df_per_strike_quantity_next, df_settlement_near, df_settlement_next, tuple_vix, tuple_vix_futures)\n",
    "\n",
    "\n",
    "        df_per_strike_quantity_near['vix_futures_on_trade_date'] = vix_futures_on_trade_date\n",
    "        df_per_strike_quantity_near['vix_futures_on_settlement_date'] = vix_futures_on_settlement_date\n",
    "        df_per_strike_quantity_next['vix_futures_on_trade_date'] = vix_futures_on_trade_date\n",
    "        df_per_strike_quantity_next['vix_futures_on_settlement_date'] = vix_futures_on_settlement_date\n",
    "\n",
    "        # if vix_futures_on_trade_date > vix :\n",
    "        #     df_per_strike_quantity_near['strategy']  = \"Buy Basket sell Futures\"\n",
    "        #     df_per_strike_quantity_near['future_P&L'] = vix_futures_on_trade_date - vix_futures_on_settlement_date\n",
    "        #     df_per_strike_quantity_near['P&L'] = (df_per_strike_quantity_near['quantity'] * (df_per_strike_quantity_near['settlement_day_prices'] - df_per_strike_quantity_near['mid_quote'])).sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date)\n",
    "            \n",
    "        #     df_per_strike_quantity_next['strategy']  = \"Buy Basket sell Futures\"\n",
    "        #     df_per_strike_quantity_next['future_P&L'] = vix_futures_on_trade_date - vix_futures_on_settlement_date\n",
    "        #     df_per_strike_quantity_next['P&L'] = (df_per_strike_quantity_next['quantity'] * (df_per_strike_quantity_next['settlement_day_prices'] - df_per_strike_quantity_next['mid_quote'])).sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date  )\n",
    "            \n",
    "        #     # combined_df['strategy']  = \"Buy Basket sell Futures\"\n",
    "        #     # combined_df['future_P&L'] = vix_futures_on_trade_date - vix_futures_on_settlement_date\n",
    "        #     # combined_df['P&L'] = (combined_df['quantity'] * (combined_df['settlement_day_prices'] - combined_df['mid_quote'])).sum() +(vix_futures_on_trade_date - vix_futures_on_settlement_date  )\n",
    "            \n",
    "        # else:\n",
    "        #     df_per_strike_quantity_near['strategy']  = \"Buy Vix futures sell Basket\"\n",
    "        #     df_per_strike_quantity_near['per_strike_P&L'] = df_per_strike_quantity_near['per_strike_P&L'] * -1\n",
    "        #     df_per_strike_quantity_near['future_P&L'] = vix_futures_on_settlement_date - vix_futures_on_trade_date\n",
    "        #     df_per_strike_quantity_near['P&L'] = (df_per_strike_quantity_near['quantity'] * (df_per_strike_quantity_near['mid_quote'] - df_per_strike_quantity_near['settlement_day_prices'])).sum() + (vix_futures_on_settlement_date - vix_futures_on_trade_date)\n",
    "            \n",
    "            \n",
    "        #     df_per_strike_quantity_next['strategy']  = \"Buy Vix futures sell Basket\"\n",
    "        #     df_per_strike_quantity_next['per_strike_P&L'] = df_per_strike_quantity_next['per_strike_P&L'] * -1\n",
    "        #     df_per_strike_quantity_next['future_P&L'] = vix_futures_on_settlement_date - vix_futures_on_trade_date\n",
    "        #     df_per_strike_quantity_next['P&L'] = (df_per_strike_quantity_next['quantity'] * (df_per_strike_quantity_next['settlement_day_prices'] - df_per_strike_quantity_next['mid_quote'])).sum() + (vix_futures_on_settlement_date - vix_futures_on_trade_date  )\n",
    "            \n",
    "        df_per_strike_quantity_near, df_per_strike_quantity_next, _ = calculate_pl_for_the_day(vix, df_per_strike_quantity_near, df_per_strike_quantity_next)\n",
    "        \n",
    "\n",
    "        df_per_strike_quantity_near = add_vol_and_delta(df_per_strike_quantity_near,formatted_trade_date_str, option_expiry_near)\n",
    "        df_per_strike_quantity_next = add_vol_and_delta(df_per_strike_quantity_next,formatted_trade_date_str, option_expiry_next)\n",
    "        \n",
    "        combined_df = pd.concat([df_per_strike_quantity_near, df_per_strike_quantity_next], ignore_index=True)\n",
    "        \n",
    "        combined_df['P&L'] = combined_df['per_strike_P&L'].sum()  + combined_df['future_P&L'].values[0]\n",
    "    \n",
    "\n",
    "        save_df_to_csv(df_per_strike_quantity_near, f'./result-set/{observation_date}/{ins_type}/dataset_{option_expiry_near}.csv')\n",
    "        save_df_to_csv(df_per_strike_quantity_next, f'./result-set/{observation_date}/{ins_type}/dataset_{option_expiry_next}.csv')\n",
    "        save_df_to_csv(combined_df, f'./result-set/{observation_date}/{ins_type}/consolidated_dataset_{on_day.date()}.csv')\n",
    "\n",
    "        basket_near_total = df_per_strike_quantity_near['per_strike_P&L'].sum()\n",
    "        basket_next_total = df_per_strike_quantity_next['per_strike_P&L'].sum()\n",
    "        top_level_pl_df =  create_top_level_pl_df(combined_df, formatted_trade_date_str, basket_near_total, basket_next_total, vix)\n",
    "        \n",
    "        save_df_to_csv(top_level_pl_df, f'./result-set/P&L-across-days/top_level_pl_{formatted_trade_date_str}.csv')\n",
    "\n",
    "        #######D not move this code up it's a hack for timebeing to get the abridged dataset#######################\n",
    "\n",
    "        df_per_strike_quantity_near = add_left_overs_for_future_ref(df_per_strike_quantity_near, df_near)\n",
    "        df_per_strike_quantity_next = add_left_overs_for_future_ref(df_per_strike_quantity_next, df_next)\n",
    "        #####################################hack ends#########################################################\n",
    "\n",
    "\n",
    "#######################################################New Block######################################################\n",
    "        \n",
    "        \n",
    "        abridged_df_near = filter_delta_across_terms(df_per_strike_quantity_near).copy()\n",
    "        abridged_df_next = filter_delta_across_terms(df_per_strike_quantity_next).copy()\n",
    "        \n",
    "        abridged_df_near = abridged_df_near[['strike', 'option_type', 'bid', 'ask', 'px_last']]\n",
    "        abridged_df_next = abridged_df_next[['strike', 'option_type', 'bid', 'ask', 'px_last']]\n",
    "\n",
    "        vix_new, df_abridged_near, df_abridged_next, df_vix_abridged_near, df_vix_abridged_next, option_expiry_near, option_expiry_next = spawn_backtest(vix_future_settlement_day, on_day, \n",
    "                                                                                                  existing_df_near=abridged_df_near, existing_df_next=abridged_df_next)\n",
    "        \n",
    "        df_vix_abridged_near = df_vix_abridged_near[['strike', 'option_type', 'bid', 'ask','mid_quote','per_strike_constants' ]].copy()\n",
    "        df_vix_abridged_next = df_vix_abridged_next[['strike', 'option_type', 'bid', 'ask','mid_quote', 'per_strike_constants']].copy()\n",
    "        tuple_vix_new = (vix, vix_new)\n",
    "        \n",
    "        df_vix_abridged_near, df_vix_abridged_next =  populate_quantity_prices_other_details(df_vix_abridged_near, df_vix_abridged_next, \n",
    "                                                                    df_settlement_near, df_settlement_next, tuple_vix_new, tuple_vix_futures)\n",
    "        \n",
    "        df_vix_abridged_near, df_vix_abridged_next, df_combined_abridged = calculate_pl_for_the_day(vix, df_vix_abridged_near, df_vix_abridged_next)\n",
    "                                                                                                             \n",
    "        \n",
    "        save_df_to_csv(df_vix_abridged_near, f'./result-set/{observation_date}/{ins_type}/abridged/abridged_dataset_{option_expiry_near}.csv')\n",
    "        save_df_to_csv(df_vix_abridged_next, f'./result-set/{observation_date}/{ins_type}/abridged/abridged_dataset_{option_expiry_next}.csv')\n",
    "        save_df_to_csv(df_combined_abridged, f'./result-set/{observation_date}/{ins_type}/abridged/abridged_consolidated_dataset_{on_day.date()}.csv')\n",
    "\n",
    "        basket_abridged_near_total = df_vix_abridged_near['per_strike_P&L'].sum()\n",
    "        basket_abridged_next_total = df_vix_abridged_next['per_strike_P&L'].sum()\n",
    "\n",
    "        top_level_pl_df =  create_top_level_pl_df(df_combined_abridged, formatted_trade_date_str, basket_abridged_near_total, basket_abridged_next_total, vix)\n",
    "        \n",
    "        save_df_to_csv(top_level_pl_df, f'./result-set/P&L-across-days/abridged/top_level_pl_{formatted_trade_date_str}.csv')\n",
    "                                                    \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred on {year}-{month}-{day}: {e}\")\n",
    "        return None\n",
    "\n",
    "results = {}\n",
    "error_urls = []\n",
    "business_days = pd.bdate_range(start='2023-02-07', end='2023-02-07')\n",
    "for day in business_days:\n",
    "    result = run_backtest(day.year, day.month, day.day)\n",
    "\n",
    "with open('error_urls.txt', 'w') as f:\n",
    "    for url in error_urls:\n",
    "        f.write(url + '\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_near =pd.read_csv('./result-set/2023-02-07/future/dataset_20230317.csv')\n",
    "df_next = pd.read_csv('./result-set/2023-02-07/future/dataset_20230324.csv')\n",
    "df_consolidated = pd.concat([df_near, df_next], ignore_index=True)\n",
    "\n",
    "df_consolidated.to_csv('./result-set/2023-02-07/future/dataset_consolidated.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
